---
output: html_document
---

# artiklid ja projektid

- projektid ja sammud jooksvalt https://docs.google.com/spreadsheets/d/1vDZuLCNXWHVTU86SQtzelLR23VnNbq3QZ4OgrLp-2pY/edit#gid=0

- kui veel colex või tradeoffist kirjutada, siis nüüd värvid diakroonliselt ka tehtud: https://www.biorxiv.org/content/10.1101/2021.11.03.467047v1


# Aesthetic complexity suur artikkel

- kunst
- film: kas freimi haaval või videoeffektid+compress
- muusika: kas spektogrammid või otse helieffektid+compress. kordumist saaks pmst ka teha kui lõigata jupid helist välja, a la sekund, 5sek, minut, pooleks, ja siis kompress-suurus korrutada; kui kordub nt motiiv siis peaks see peegelduma. helieffektid: hi, lo, mid; sama helivaljusega/amplitude; overdrive; FFT; soundgen::vibrato
- linnud ja loomahääled
- aga ka üldised soundscape'id, ökoloogiline komplekssus
- youtube: kas mõni kaader või terve video
- mängud: steami screenshottidest
- mood: väljalõigete skännid, Max
- kaardid
- pmst keel saaks ka, kui mõelda välja mingid keele-filtrid/transformid.
- PCA asemel: kui transformid ei korrelleeru eriti, siis pmst võiks ka keskmise plottida, ja/või nt ühe neist eraldi kõrvale, mingi mis hästi eristab, nt blur vms. nt mingi plott kus filmiminutid (norm?) xteljel ja komplekssus y, rolling mean, äkki on mingi süstemaatilisus. sama saaks audioga, ja saaks korrelleerida. a la mingi michael bay oleks ilmselt pidev lärm ja müra. peaks portsu filme piraatima.
- liikuva puhul (film, muss, dialoog), mida teha kui on kordamööda vaikus/pimedus ja keerukus/müra/pikad laused? siis rolling mean pole informatiivne, mingi sd peaks ka olema. ja kas frame või keyframe või shot?
- "AUVANA: An Automated Video Analysis Tool for Visual Complexity" ka et mitu parem kui üks. "Rather than being a single construct, we hypothesize that video visual complexity is more likely a multilayered and multidimensional construct." Pmst juba teevad seda, erinevad edge detection jms asjad ka, aga rohkem et saaks eraldi asju vaadata, kui et ühtne kolmo komplekssus. canny jms on, aga mitte nende kompress, st ei ole transform+compress.
- "Compressed File Length Predicts Search Time and Errors on Visual Displays" radarid, "Compressed file length is analogous to algorithmic complexity, a theoretical measure of bit string complexity. It predicts both subjective complexity judgments (previous research) and search performance (this study) for a set of static marine electronic displays. The data suggest that compressed file length will predict minimum anticipated performance in a range of applied visual search tasks".
- kas kuidagi saaks cinandoga siduda, et festivali kaupa võrrelda?

# kultuurimõtted

- midagi selle tvtropes'iga. pmst saaks teha vektorid, saaks troopide advectionit vs arvutada, võrrelda tv vs mängud vs filmid jne, kui palju muutus on advection zanrites (logmuutuse-adv korrelatsioon), mingi liikuva akna teha, keskmine võtta (-1,-2,...-n aknast). Tundub et eriti midagi pole (https://arxiv.org/abs/2006.05380, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8011780/)
- tindris on tagid, kui need on riigiti samad, siis saaks kaevandada portsu profiile üle maailma ja teha globaalset huvialade-antropoloogiat. need diskreetsetena jällegi erineva sarnasusega, aga saaks teha sama mis festivalidega ja panna mingisse latentsesse ruumi. ja/või sem võrdlus, kus miski millega koosesineb (ppmi või lambda), ilmselt seal ka mingeid globaalseid erinevusi. kui pildid ka, saaks vaadata kas erinevates kohtades korreleeruvad (on ennustatavad) tagid rohkem või vähem. soovõrdlus ka, kas mingid korreleeruvad, ja kas riigiti erinevad.


# Newsreels

- uuesti topikmudel, Mikhaili puhastatud andmed + sentence embedding + hdbscan et oleks natuke hierarhilised klastrid, aga sama tfidf märksõnade asi, aga et siis oleks nii peaklastrile kui alamklastritele. ja siis need värvidega kenasti plotil kuidagi.



# keelemõtted

- sama transform+compress keelele: byte pair encoding mitme parameetriga kui transform, ja siis nende indeksite kompress/zip. ?

- Every text – that is, everything that is said or written – unfolds in some context of use; furthermore, it is the uses of language that, over tens of thousands of generatons, have shaped the system. Language has evolved to satisfy human needs; and the way it is organized is functional with respect to these needs.  (Halliday, M.A.K. (1985) An Introduction to Functional Grammar. London: Edward Arnold, xiii.)


-   Kas sama compressioni ideed saaks keelele rakendada? varemased
    katsetused a la see evolangi workshop on igaüks erinevat lähenemist
    (ngrammid, süntaks, wals, zlib jne) promonud, aga miks mitte need
    kõik võtta, samale skaalale ajada, PCA teha ja davai ongi. Ja
    võrdluseks samamoodi nurgad, et mis oleks kui oleks muidu
    harjukeskmine keel, aga variaabel x või y (misiganes korreleerub
    hästi pc1, pc2ga) oleks maksimaalselt lihtne või keeruline, ja siis
    et kui kõik variaablid oleks min või max - sealt tuleks kenasti et
    tegelikult võrreldes hüpoteetiliste ekstreemidega on kõik keeled
    lihtsad (aga samas ka piisavalt keerulised). saaks ka võtta x keele
    nt inglise nurga alt, mis on keerulisem/erinevam/sarnasem. ja keeled
    mis on mulli perifeerias - mis neis see ekstra lihtne/keeruline
    omadus on. Et olulisem on isegi see piiritletus, kui absoluutne "x
    keel on keerulisem kui y keel". vt ka
    <http://www.christianbentz.de/MLC2018/proceedings.pdf>
    <https://link.springer.com/chapter/10.1007/978-3-319-19258-1_1>




-   diakroonia: kui saaks keele erinevate aegade korpuse saaks
        liikumist vaadata. korpusteks ilmselt mingid võrreldavad tükid a
        la piiblid, deklaratsioonid jms paralleelne, et võrreldav oleks?
        Piiblid: 830
        <http://www.lrec-conf.org/proceedings/lrec2014/pdf/220_Paper.pdf>
        või 960
        [\<https://vlo.clarin.eu/record/urn_58_cts_58_pbc_58_bible;jsessionid=A430466E7B97E07D4E7F6F2C7A0A869F?0>](https://vlo.clarin.eu/record/urn_58_cts_58_pbc_58_bible;jsessionid=A430466E7B97E07D4E7F6F2C7A0A869F?0){.uri}
        ; võtta euroopa jms suuremate keelte peale suuremad ka eraldi,
        ja näidata et suurem korpus ei muuda tulemust oluliselt?

-   kas information lossi saaks umbes nagu mollica tense,
        evidentiality, number - kõik mis eri spetsifitseeri mingit asja
        on järelikult hägused - teha walsi peal?
-   mida saab paljudele: type/token, ja phonetic segments
        type/token, predictability of sound; Kolmogorov complexity (text
        compression algode kaudu, gzip - a ütleb et oleneb
        kirjasüsteemist nt hiina peal ei tööta), ngram perplexity,
        D_structure (gzipitud tekst/mingite asendustega gzipitud tekst)
-   mida saab osadele: Mean size of paradigm (kui on
        lemmatiseerija(ka stemmer?)), Morphological feature entropy ja
        POS tag n-gram perplexity (kui on POS), Conditional feature
        entropy (kui on paradigmad), lemma==wordform (type/token),
        syntactic dependency length and dep "flux weight"; ja siis WALSi
        kategooriad, kõik mis on järjestatavad on davai. Kuidagi CLICS
        ka sisse, seal on sõnavara-komplekssus - aga samas väga
        eurokeskne, ilmselt mujal keeltes on komplekssus lihtsalt teise
        koha peal... peaks seda kuidagi kontrollima või normaliseerima.
-   kõigil pole treebanki ja lemmasid, a kas wordpiece oleks äkki ok
        asendus, mitme erineva väärtusega? ja mingid asjad veel kus
        tähti asendada ja vaadata kuidas komplekssus muutub? (nt kui on
        laadivahedus/tüvemuutus, seal on regulaarsus, kui nt topelttähed
        ära võtta (sh nt läti pikad tähed) ja siis teha type/token jms).
-   Tamar'i Assessing Integrative Complexity as a predictor of
        morphological learning using neural networks and artificial
        language learning - saaks osadele rakendada, kus paradigmad
        kättesaadavad

-   Max küsib kas oleks mõtet klasterdada sõnatähenduste muutusi nagu
    Rosenfeldi plot kus 4 lähedasema sõna sarnasus 100a jooksul, neist
    teha 4*nbin vektor. aga milleks..? et ei ajaks sassi tähtkujusid ja
    tegelikke tähelastreid. ja kuidas kvalit. semantikamuutuste
    teooriatega siduda? äkki simuda ideaalsed mudelid?

-   kui teha peaks võtma sämpliks nii et naabrid ei kattu, et saaks erinevatest semruumi nurkadest.

-   efficiency: pmst ka ju, ei saa kõrge complexity olla kui sõnapikkus
    on 1, st mingi pikkusega x tähtede arv sõnu on vaja mingi compl
    jaoks.

-   Alex kirjutas emoji semmuutustest: **Semantic Journeys: Quantifying
    Change in Emoji Meaning from 2012-2018**


## Sagedus ja tähendus, Garry & Arturs

- G tahab võrrelda tähenduste/tähendusväljade sagedust keelte vahel. A tahab nagu mingeid data-driven tähendusi/kontsepte.
- ilmselt saaks: multikeelne bert, embeddida wordfreq'ist ports sõnapaare (et saaks erinevaid tähendusi polüseemsetel), ilmselt mitte kõik kombod aga mingi kesksagedusega target set ja samplida paarilisi (ja mingi x korrata seda), need vektorid -> nt k=10 umap -> (h)dbscan
- hierarhiline oleks ilmselt huvitavam? saaks võrrelda mis tasemel keeled erinevad; ja siis poleks noise-klastreid vist, lõpuks oleks kõik ühes; aga jällegi kaalumine vist keerulisem?
- selle klastrid oleks tähendusväljad, ja siis saaks sõnasagedused nende vahel ära kaaluda - et kui üks sõna mitmes klastris, siis sagedus ära jagada, kaal == mitu n korda selles klastris on. ja siis klastris keelte kaupa sagedus või log sagedus kokku liita ja võrrelda keelte vahel. a mis siis saab kui on noise/outlier üksinda, see ilmselt pole suure sagedusega, seega kas see peaks terve klastri kaalu saama? (või peaks kaal olema omakorda tagurpidi kaalutud klastri suurusega, kui n=1 siis maha kaalutud?)
- peab arvestama et osades keeltes mitu sõna, aga osades üks sõna mitu vormi a la eesti. aga vähemalt see on parem kui nt clicksi kasutades, siis siis loeks ainult nom.sg, või siis peaks olema kas lemmatiseeritud sagedused või sünteesitud vormid.


## Kenny, colexification & complexity järgmine asi

- uus preprint mida viidata: https://arxiv.org/abs/2208.10384
- 2015 aga võibolla ka; mingi network mudel, viitab ainult Steelsi ja Piantadosit: Ambiguity in language networks Ricard V. Solé
- Experiment: half short, click more to send longer, all dissimilar meanings; alt cond where no effort to send long
- context as additional (given?) word?. see piantadosi ambiguous words efficient can resuse
- short words more senses, see if somebody has updated zipf. could do little corpus thing.
- some concepts more often, so shorter. but nobody counts meanings, just forms.
- 9 meanings, 6 signals. 3 long 3 short words.
- What's the causal graph, overaching hypothesis? length, sense and signal freq, colex.


## viidata

- Tracing Semantic Variation in Slang. Zhewei Sun, Yang Xu. Pmst veel üks komm.need asi, pakuvad kuidas sagedusest kätte saada, mingi voting mudel, "find the majority vote scheme to be robust in our experiments as frequency counts of common words could otherwise dominate the estimates."




# Loomkommunikatsioon+masinõpe, evolang, meercats & gorillas, laste hällikõne


- MAG https://arxiv.org/abs/1908.05787 Integrating Multimodal Information in Large Pretrained Transformers
- Florian Deepmindis fstrub@deepmind.com. contrastive learning.
- võibolla ppmi+svd, Improving Distributional Similarity with Lessons Learned from Word Embeddings, Omer Levy, Yoav Goldberg, Ido Dagan, TACL 2015
- st andrews grupp.

- samas see mida Linask kirjeldab on sarnane, päris aru ei saa mida lapsed omaette jutustavad, aga äkki saaks midagi tuletada sama moodi.


# Expressivity vs complexity

-   võibolla sellest saaks position paperi - et palju asju taandub
    sellele tradeoffile (aga tihti need dimensioonid on ise
    mitmeharulised). All of human culture as a tradeoff between
    complexity and expressivity.

-   *ok äkki teeks hoopis üks tase ülespoole: informativeness on
    lihtsalt üks expressivity tüüpe - ja muusikas/kunstis on mingid
    teistmoodi pressurid kui keeles (kus on tähendus ja sõnum oluline),
    kunstis on oluline olla ekspressiivne ja midagi uut anda. või Simoni
    tööriistanäide: lihtne oleks üks tööriist kõige jaoks, kompleksne
    oleks iga väikse töö jaoks eraldi tööriist, optimaalne on seal
    kuskil vahel, paras ports tööriistu.*

    -   siis pole vaja mingid tõlgendamise-meetrikut a la see
        emotsiooni-asi, piisab mingist komputatsionaalsest
        uuenduslikkusest, wikiartist saab enamvähem ajastu malli kätte,
        nt põlvkonna (20a) kaupa teha (umbes mis Maxil juba olemas on,
        mingi sarnasus, need erinevad kokku panna).
    -   kui saaks genereerida selle latent space'i kuidagi nendest
        komplekssuse jms vektoritest, siis liikumine seal olekski äkki
        see expressivity, liigub ruumi kus (viimasel ajal) pole midagi
        olnud. aga mingi suva lihtsa asjaga raske sinna liikuda, kui
        pole just radikaalselt lihtne nagu must ruut...? samas ei tohiks
        komplekssusega autokorrelleeruda, muidu nagu vähe mõttetu. seega
        pigem need deep learning asjad? ilmselt/äkki haakuks Mar'i
        asjadega ka?
    -   aga mingid asjad on ikkagi rohkem keele moodi/informatiivsus, nt
        kui saaks filmiandmebaaside tagid, firmanimed. või äkki siis
        saaks filmid ka teha, imdb keywordsid oleks see ruum?
    -   Simon mainis et Monica tegeleb sellega, peaks rääkima.

-   coding length kirby et al 2015, sum of negative log2s of
    probbilities of signals

-   communication: aga äkki mitte see et kas segadus, vaid see et kas
    agent valib suva signaali või sellise mida \*tõenäoliselt (RSA!)
    teised oskavad interpreteerida.

-   frontier/optimality estimation: vt
    <https://semanticsarchive.net/Archive/DNmNDAxN/Denic-et-al-Indefinites-SALT.pdf>
    ja Steinert-Threlkeld, Shane. 2019. Quantifiers in natural language
    optimize the simplicity/informativeness trade-off. Pmst simulatsioon
    kus keeled tekitavad uusi keeli, peaks tehtav olema. Ja kaugus on
    lihtsalt eukleidiline (ilmselt peaks normaliseerima teljed? või just
    vastupidi mitte?)

-   vt Comparable information rates across the human communicative niche
    <https://advances.sciencemag.org/content/5/9/eaaw2594.full> ##
    muusika

## muusika


- dataset: annoteeritud jazz, saaks instrumenti ennustada: https://github.com/stefan-balke/jsd

- R'is on tuneR ja spectral, seal on filter.fft funktsioon (ekvaliser?)
- https://rdrr.io/cran/seewave/man/ffilter.html
- soundgen 

-   vt musical ngrams, ja keegi Marco Nardelli Santa Fe's.
-   vt <https://theglobaljukebox.org/> - lauluklipid üle maailma, suur
    andmebaas
- võibolla pikkus on suva, võtta lihtsalt ratiod ja saab võrrelda 1.5min punki ja 10min sünfooniat (kui kordused struktuuris pole olulised, ainult keerukus momendi kaupa). samas saab ka tükkideks võtta ja vaadata kas sünfoonia kõik osad on samas kohas ruumis, või mõni osa on hevi metal.

-   äkki akordid, min vs maj, informatiivsus mturkist kas kurb või
    rõõmus heli, complekssus lihtsalt mitu nooti(?). 1 vs 1,3 vs 1,3,5
    vs 1,3,x,y jne. 1234567 on müra juba. Nurkadesse puhas 1 toon ja 12
    tooni korraga.

    -   ja siis võtta mingid midid/noodid ja näidata et suur osa
        muusikast (akordid kus on 1,3) on pigem see et pole müra ja on
        optimaalsed st mitte 1,2,3,7 vms.
    -   mingi single chords durhami oma on
    -   <http://www2.projects.science.uu.nl/memotion/emotifydata/> -
        sealt sõnadega lood välja, ja võibolla need paar kahtlased
        tunnused, ja siis vektorite divergents või lihtsalt sd on
        information loss, ehk palju ambivalentsi on
    -   x %>% group_by(track.id) %>% summarise_at(vars(3:10), sd) %>%
        ungroup() %>% select(-1) %>% apply(1, mean) %>% hist()
    -   VÕI: mitte ainult pos-neg vaid valence+arousal, vms muud 4
        nurka. siis 1,3 on küll valents selge aga mingi muu mitte. ja
        mitte kõik kombod, aga see-eest paarkümmend hindajat per
        stiiumul, et ambivalentsi skoor selgem tuleks.
    -   kvaliteedikontroll: peab kuulma mingit numbrit kõigepeal ja
        sisestama, kui feil siis feil.
    -   kas nurkade mitte katmine on probleem..? või interpoleerida
        kuidagi need - või, hoopis natuke juurde turkida neid, võtta
        samad kategooriad aga anda müra, puhas toon, midagi
        megakeerulist? hmm samas need oleks nagu ette teada juba..?

-   A Set of 200 Musical Stimuli Varying in Balance, Contour, Symmetry,
    and Complexity: Behavioral and Computational Assessments - aga kõrge
    agreement just, ja kõik C major.

-   <https://www.researchgate.net/publication/337445116_Information-theoretic_Modeling_of_Perceived_Musical_Complexity> -
    Idyom mudel githubis, aga peab treenima millegi peal, ja töötab
    ainult midi peal. annoteeritud andmed of väikse hulga muusikute
    poolt.

-   hoopis teine variant:
    <https://royalsocietypublishing.org/doi/10.1098/rsos.170952> - sõnad
    paari panna akordidega, ja teha sõnadele/ridadele sentiment analysis
    (või lihtsalt mappida embeddingutele), osad akordid on
    geneerilisemad, komplekssemad äkki täpsemad? või teha
    akordi-bigrammid, et siis üleminekud ja kõik sõnad mis neil kokku
    on. ja muidugi 1-5 / C-G seda on kõik täis, aga saaks võtta mingi
    conditional estimate'i - arvestades palju mingit bigrammi on, palju
    variatsiooni, kas rohkem või vähem kui ennustatud, pmst residual?
    aaaaaaaga seal probleem, paljud akordid tabid on lihtsustatud maj
    min akordideks. võibolla lihtsustada edasi, igasusu sus, dim, 7 maha
    ka?

-   plaan oli kirjutada

Hi Mason! I got a science question about music, and I figure you might
be the person to ask. What would be a good way to measure information
loss/ambiguity, and also complexity, in music?

In the sense of Kemp et al 2020, Semantic typology and efficient
communication
(<http://www.cs.toronto.edu/~yangxu/kemp_xu_regier_2017_ec.pdf>). I
don't know if you're familiar with that strand of research, so in short:
in language, it has been observed that many semantic domains like color
or kinship terms are close to the optimal frontier on the
informativity/complexity axis - language learning requires simplicity,
but successful communication requires as low information loss as
possible, hence requires complexity. So a kinship system with a single
word for all relatives besides the immediate family would be very
simple, but would induce error/loss in communication; while a system
that has a unique term for every relative, distinguishing maternal and
paternal grandparents, nieces etc - would be very complex and hard to
learn, but indeed very unambiguous. So there's a sweet spot which is
where most languages lie.

I want to try that on other cumulative cultural domains, including
(instrumental) music. In music (leaving lyrics aside), informativeness
would be, I guess, how unambiguously a piece of music would be
interpreted by different listeners. So if it's just a monotone beat,
very simple, but you ask what people hear there, and everybody says
different things. A very clearly major scale upbeat tune, everybody will
say yeah it's a happy tune. So I found some research on crowdsourced
valence ratings of music, and some do have \~10 raters per piece, so the
variance there is a proxy to ambiguity (although more people would be
nice) - but the pieces tend to be 30-60 seconds, a lot can happen in
that span. There's one paper on the valence of single chords
(Laddelma&Eerola 2014), but they have only a few chords and data is not
available. Do you know of any other such research/datasets? It's not
impossible I'd have to crowdsource it myself, something like single
chrords, or few-note short melodies.

The other question is complexity. So in visual art, there's research
showing that simple GIF compression correlates generally quite will with
people's ratings of the complexity of a painting or photo. Any ides how
to measure that with music though? With chords, sure, just the number of
notes in it - but with longer sequences or 30sec exerpts...? The
datasets are already typocally mp3, and I'm not sure it'd be a good idea
anyway. I found another paper (same guy, Eerola - Expectancy-Violation
and Information-Theoretic Models of Melodic Complexity) that compares
different models of musical complexity but this looks super complex and
still not very promising. There's also Celemente et al 2020 (A Set of
200 Musical Stimuli Varying in Balance, Contour, Symmetry, and
Complexity), but they specifically aim at unambiguous short sequences,
and everything is in C major, so I wouldn't know how to do
informativeness/ambiguity on that.

------------------------------------------------------------------------


### viidata

- https://royalsocietypublishing.org/doi/10.1098/rsos.150081
- Ana Clemente https://evocoghum.uib.es/ana-clemente/



## muusika aga sõnad ainult

-   acerbi mingi laulusõnade komplekssus on juba olemas
-   informativeness äkki mingi lyrics meanings misiganes arvamuste
    variatsiooni järgi.
-   kirjutasin songmeanings.com ja küsisin api ligipääsu.

## kunst

-   AGA: võtaks ajaloolise ja wikiarti asemel hoopis instagrammi ja
    generative arti: mingeid konkreetseid objekte pole mida
    klassifitseerida, samas on olemas laigid jms, saaks teha observed
    (laigid) / expected (kasutaja followeride arv) edukuse

    -   a kas sellist kunsti on tehtud: et teeks mingid generative pildi
        (nt perlin noise), ja siis iterated learning, kus kunstnikud
        joonistavad ümber eelmise pilti, vaadata kuju välja jõuab. ja
        siis mõõdaks entroopia, compressioni jms muutusi. mingi
        blockchain vms asi peaks olema mis korjaks infi et kes on mis
        versiooni teinud, või lihtsalt logi sisse ja ütle. ja saada
        järgmisele edasi. kui ei saada mingi aja jooksul siis läheb
        kuhugi mujale, peaks ilmselt igaühe käest mitu kontakti korjama.
        ilmselt mingid networki effektid ka.

-   vt veebruaris scil lehelt Distributional semantic representations of
    visual concepts. Geoff Bacon, Terry Regier and Noga Zaslavsky.

-   vt Quantifying Creativity in Art Networks
    <https://arxiv.org/pdf/1506.00711.pdf> , varasem samadelt influence
    kohta: <https://arxiv.org/pdf/1408.3218.pdf>

-   äkki hoopis ikoonid või liiklusmärgid

-   max pole kindel kas see 19-kategooriaga emotsiooni asi on parim
    millega kunsti iseloomustada

-   peab olema selge, et see complexity ei ole pildi tootmise
    complexity!

### meetod

-   birkhoff aesthetic measure as third? vt maxi landscape paperit

-   oluline: seleta miks 2nd order sim on parem kui 1st order
    (komolimentaarsed sõnad), aga kui cos vs eucl erinevad, näita lisas.
    max arvab et maatriksi esitamine oleks oluline.

-   kas pilt on \~\~ kinship süsteem? või pigem pildi osa...

-   jsd cos/eucl asemel?

-   gif kui komplekssus:
    <https://pdfs.semanticscholar.org/d9e0/1b48f2c32ccfb224ab906f70490f2687614f.pdf>

-   gif+edge detection parem, mingi joint mudel ja rmse:
    <https://evocog.org/wp-content/uploads/2017/01/Machado-2015-nadal-complejidad-preferencia-arte-est%C3%A9tica.pdf>
    (sobel edges detectioni saaks siit:
    <https://www.rdocumentation.org/packages/wvtool/versions/1.0/topics/edge.detect>)

-   tee gif ja 90\* keeratud gif, võib erineda

-   sarnane asi, potrace vektorisatsioon+zip ja teine mingi perimetric
    ratio of inked surface to the perimeter of this inked surface;
    korreleeruvad:
    <https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0220793>

-   andmed: <https://www.aclweb.org/anthology/L18-1197.pdf> WikiArt
    Emotions: An Annotated Dataset of Emotions Evoked by Art
    <http://saifmohammad.com/WebPages/wikiartemotions.html>

    -   seal vist ainult mingi põhiline üks sõna, aga küsiti mitut.
        taandada pos-neg-other valentsile mis artiklis kirjeldatud,
        muidu sõnu liiga palju? või all-dataset, aga seal on mingid
        protsendid vms.
    -   kus on inimese nägu, on emotsioon kohe selgem, aga gif seda ei
        erista - peaks neid eraldi käsitlema? tag on peal kui nägu. või
        võttagi ainult mitte-näopildid!
    -   ja siis gif-kompressiooni komplekssus. ainuke probleem et
        wikiart juba on kompressitud...?

-   see kolmas dimensioon, et kohati äkki ei pea olema optimaalne kui on
    äge: äkki see on mingi loovus/innovatsioon, vt
    <https://www.researchgate.net/publication/277723286_Quantifying_Creativity_in_Art_Networks>

-   WikiArt-Emotions-All.csv - tundub et nägude entroopia pole erinev,
    isegi suts suurem; ja renessants suurem kui modern? äkki liiga suur
    ajaline lõhe? peaks nagunii näitama stiile eraldi ka.

-   miks kasutada ainult pilte ilma pealkirjadeta:
    <http://journal.sjdm.org/19/190712/jdm190712.pdf> - pealkirjad
    oluliselt muudavad abstraktse kunsti tõlgendust (neil fookuses
    profoundness)

-   magick + tesseract, kontrollida et teksti peal poleks

-   võibolla entropy pole parim, entropy(c(1,1,1,0,0,0,0,0,0,0)) (kõik
    arvasid et esimesed kolm) ja entropy(c(0.3,0.3,0.3,0,0,0,0,0,0,0))
    (10 jagunes kolmeks täitsa erinevaks arvamuseks) on sama skooriga.
    samas sd annaks 1,1,1le 4x suurema skoori, peaks olema vastupidi.

-   peaks olema: kui 1 ainult, siis 0, kui 10x0.1, siis 1; ja > 0.5,0.5.
    Aga 1,1,0,0 peaks == 1,0,0,0.

-   kui kaugel on skoor lahkarvamusest: 0.5-abs(seq(0,1,0.1)-0.5) ja
    siis selle summa. aga pole päris see, 10x0.1 on ainult natuke suurem
    kui 3x0.3 oma.

-   sum((0.5-abs(c-0.5))) / max(c)

<https://use2-uploads3.wikiart.org/images/jorg-immendorff/society-of-deficiency-1990.jpg>

<https://use2-uploads4.wikiart.org/00103/images/maarten-de-vos/the-rape-of-europa-1590.jpg>
- semicopy of titian

-   isegi kui mingi 1590 mütoloogilised sümboolsed välja jätta, on ikka
    nt
    <https://use2-uploads0.wikiart.org/images/jean-michel-basquiat/history-of-the-black-people.jpg>
    kompleksne aga segane

-   black and white complexity
    <https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0207879>
    äkki see eraldi ja chroma sinna juurde?

-   vt imagefluency pakett, complexity() - ja gif peaks ka keerama 90
    kraadi et võib erineda!!!

-   kui see compression=>prediction siis vektorid aga peaks tuunima mis
    on paremad; ja/või principal components/factors

-   et äkki efficiency bias on veel kolmas - osad maalid keeruline
    teha - seda saaks hinnata, võtta mingi väike valim ploti erinevatest
    sektoritest ja küsida kunstiteadlastelt/kunstnikelt vms kui
    keeruline sellist maali oleks teha.

### kiri Maxile 21.12.2020

But I was thinking was, so you got this information about chroma, and
about contour structure, and there's also year of creation and possibly
other metadata, and adding to those, there's this emotion elicitation
dataset (not entire wikiart like the rest, but a few thousand still;
also this is aimed for deep learning anyway, so could train a classifier
on that and label the rest of wikiart). And you mentioned how this work
of yours that you showed me is in a sense probing how much these
automated methods can act as curators, and how art can be cut and
clustered in different ways. Ok, so would that be something of interest
to the art history/visual aesthetics community: 1. take all these
measures, turn them into operable variables (e.g. the chroma layer from
your NN should probably be reduced to a lower number of say 2-3 factors,
some sort of similar aggregation with the emotion data etc) 2. then use
these variables in a multi-label classification task, to predict the
"ground-truth" (historian-assigned) label of the art piece, like it's
era, style or some other category 3. but instead of neural networks or
whatever, use something more interpretable for classification, like
random forest, which directly gives you variable importance and decision
paths, in addition to just prediction accuracy 4. the accuracy = how
much automated measures correlate with expert/historian/curator
curation/classification (assuming that's what wikiart labels are) 5. the
variable importance = which of these different measures correlates most
with said human-assigned labels (or which maybe don't correlate, but
arranging pieces using that might still make sense to humans, like your
chroma thing, i.e. could be some previously undiscovered meaningful
structure) 6. ??? 7. PROFIT (...?)

### 

## visuaal aga eksperiment

-   mustvalged pildid, paar eri stiimulit mis jooksevad selgest pildist
    randompikslitesse, mingi automaatse muutmisega, küsida mis pildil,
    komplekssus kas mustade pikslite arv ja või gif või võtta seda kui
    networki ja vastavalt mingi network complexity, ristumised on noded,
    edge pikkus ka loeb.

## kirjandus/luule

-   a fanfiction - neil skoorid küljes. tekstikomplekssus. YY Ahn rääkis
    novelty estimateist ka. samas, informativness...?? nt see Groot -
    info kadu kindlasti suur, komplekssus madal, aga innovatiivsus
    kõrge, ja seega populaarne.

## filmikategooriad

-   Vejune on pmst nõus hankima neid vist. Mh riikide filmiarhiivid.

## muud

-   What's it going to cost you?: Predicting effort vs. informativeness
    for multi-label image annotations
-   On the Informativeness of Titles 1984 - a äkki võiks teha
    teadusartiklitele sama asja - kui kompleksne vs mingi klassifikaator
    mis hindab kui paljudest artiklitest see pealkiri eraldab vms
-   midagi brändidega? taxify ja transferwise sisaldavad infot, apple
    mitte nt (samas cocacola ongi koolaks saanud ja botas botaseks; ja
    apple oli algul apple computers). informatiivsus on
    sarnasus+assotsiatiivsus(metafoor), komplekssus on sõna sisene
    jooksev surprisal, vt Adam King. tõmbaks mingi andmebaasi firmadest
    millel käive, vaataks brände/nimesid. või nt samal aastal asutatud
    firmad/brändid. suur osa on bisnes pool, aga kas optimaalsus
    ennustab midagi? Hannalt: "BFMis on muidu meediamajanduse õppejõud
    Ulrike Rohn (kes vaatab nii ettevõtteid kitsamalt kui ka
    meediamajandust laiemalt), võib-olla tema oskab sulle täpsemalt
    vastata"
-   ajaleheartiklid: Domain Agnostic Real-Valued Specificity Prediction,
    Fast and Accurate Prediction of Sentence Specificity
-   ikoonid ja emotikonid - osad väga abstraktsed, aga assotsiatsiooni
    kaudu konventsioon samas. nt mingi ravimiikoonide dataset:
    <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3785992/> - probleem
    samas et need on juba populatsioonis liikvel ja osad võivad olla
    oluliselt sagedasemad ja seega tuntumad kui teised.
-   progekeeled - dplyr nt kõrge komplekssus aga täpne/spetsiifiline.
    peaks võrdlema taski kaupa (nagu kinship)
-   või piktograafilised kirjasüsteemid? aga kust informatiivsuse saaks,
    vaevalt neid eksperimentaalselt on tehtud?
-   twitteri-handlid? vs nimed.
-   spämmkirjad? peab mingi äärmuse peal mängima, et lollikesi püüda,
    aga ilmselt mingi piir ees? saaks kuskilt lehtedelt kokku koguda mis
    neid korjavad, ära kodeerida (palju raha lubatakse, mis protsenti,
    kui keeruline ulmejutt on, mida on vaja teha), ja selle pealt teha,
    kui ekspressiivne ja kui kompleksne skeem on?
-   tänavanimed vs tänavapikkused - pikad tänavad lihtsam, vähem nimesid
    vaja mäletada; aga jälle raskem navigeerida (informatiivsus),
    lühikesed täpsemad aga rohkem mäletada (tartu/tln vs edinburgh vs
    new york). kas inimeste arv teeb seal midagi? communicative need?
    lisaks teistpidi see, et kas on deskriptiivsed nimed (lõuna-x,
    ülemine-x, esplanaad, main street), või siis mingi süsteem
    (Mannheimis olla mingi tähe-numbri kombo mis läheb piki peatänavat
    kahes suunas laiali) mis on hierarhiline ja seega lihtsam
    orienteeruda (st õpid süsteemi/grammatika mitte sõnu). kas kuskilt
    saaks andmeid/tuletada palju inimesed linnades ära eksivad? samas
    seal on palju muid sotskultuurilisi põhjuseid ilmselt veel.
-   kas on mingi parem viis seda esitada kui see kaarega scatterplot
    (eriti kui 3+ telge), ja kas seal mingit paremat statistikat on kui
    kaugus simuleeritud optimumist.
-   fake news, libauudised - kas siin ka mingi optimaalsus, midagi mida
    saaks kompressida, ja kas pärisuudised on erinevama koha peal
    libadest. sama moodi panna kokku kõikvõimalikud erinevad skoorid,
    mudelid jms.
-   arvutimängude graafika?
-   videot saaks kas freimi kaupa gif või miks mitte mingi video
    compression algoritm, saaks ju ka videole effekte/filtreid peale
    panna.
-   tviidipikkus pmst ju ka optimeerib: ekspressiivsust
    (pikem=rohkem/täpsem) vs lugejasõbralikkust (pikem=ei viitsi, ei
    jõua hallata, cognitive cost). redditis on lõputu(?) pikkus aga
    pigem on lühikesed, seega kas see struktureeritus aitab ja krutib
    pikkusevajadust väiksemaks? tvitteris ka struktuur aga mitte nii
    obvious. foorumis ja vanasti usenetid jube pikad ja postitused
    mattuvad.

## seadused

- Simon oma cudaniettekandes pakkus et võiks uurida seadussüsteemide compressionit ja systematicity't. ja kuidas transmisssion toimub sammsammult.






# Art complexity & Sebastian Ahnert

- VIIDATA pärast review'd: https://doi.org/10.3390/e24091175 WikiArtVectors: Style and Color Representations of Artworks for Cultural Analysis via Information Theoretic Measures

- mõte: amazon ja pusled, saaks panna samasse kunstimudelisse, regressioon et mis hästi müüb, ja/või lihtsalt sarnased kunstipildid välja võtta, kui open domain saaks lihtsalt müüa. aga saaks ka seletada mis dimensioonid olulised müügis. aga peaks hinda kontrollvariaablina kasutama.

- mõte: saaks mõtestada image embeddingute dimensioone, korrelleerides neid compression ensemble omadega.


## cover letter

- mention Barabasi and Manovich as too close
- mention Gregory Chaitin as possible

## saada kui valmis:

- takovich2@gmail.com - Feschchenko semiootika konvekalt
- Peeter Torop
- Francisco.sedda@gmail.com
- pau@ini.uzh.ch (Lyonist)
- Chico Camargo (tegi algoritmilisest loodusest artikli, lang evo huvi)
- Frank Schweitzer - aga äkki on revieweriks pigem.

### tehniline

-   peaks tegema mingi filtri mis on pilt neljaks (ja kese vs ääred) ja
    mõõdik on tükkide gif compressioni sd (võibolla edge_gray ka) - ehk
    eristada pilte millel on keeruline osa ja sile taust vs need mis on
    üleni keskmiselt keerulised.
-   Mõte jutuajamiselt Mikhailiga, et kui tahta liikumist, siis üks
    variant oleks lihtsalt pooleks võtta iga kunstnik, ja siis mõõta kui
    kaugel keskmiselt need pooled on, kui kaugel poole sees on
    (normaliseeritud n maaliga ja x aastatega kuidagi), ja kas need
    grupid omakorda on mingis tihedas alas (konformistid) või hajusas st
    innovaatorid.
-   Ikkagi proovida diffusion mappe? otse loadinguid ei saa, aga
    korrelatsiooni saaks variaablitega seletajaks võtta.
-   \*\* mõte: äkki ikkagi saaks expressivity ka teha - sarnasus
    eelnenud piltidele mingi pildisarnasus-meetodiga a la see Maxi
    resnet asi - et lihtsalt mingi hägune kas-sarnast-pilti-on meetod.
    komplekssus oleks mitmedimensiooniline (plotil mingi pc1+pc2) aga
    siis expressivity oleks ka, kui see sarnasus teha samuti mitme
    transformatsiooni peale - edges, color, jms. või võibolla isegi need
    samad 40+ filtrit mis compressioni puhul? st need samad gifid
    mingisse pildi-encoderisse sisse sööta, ja võrrelda kõigi teiste
    piltide sama filtrivariantidga. \*\*
-   või Linear Discriminant Analysis, Yang Xu kasutas seda oma asjas
    tähenduste peal informativenessina. et palju sa kunstnikuna (klass)
    teistest eelmistest kunstnikest erined.
-   või lihtsalt lasta mingi imageneti peal treenitud mudel peale ja
    informativeness on pmst kui mitu objekti kui suure tõenäosusega
    suudab tuvastada.
-   ports erinevaid transformatsioone ja võrdle jpeg compression suurusi
-   ok tal hoopis imagemagick filtrid ja transformatsioonid, aga
    tunduvad natuke lambid, nt edge detectioni asemel charcoal, ja mis
    point neil sin ja arcsin asjadel on? kas osad asjad äkki müra ei
    suurenda ja ei tee raskemaks hea täpsuse saamist?
-   kas saaks sinna juurde panna mõttekamad asjad nagu parem edge
    detection, chroma, võibolla see maxi neural network ka, ja teha pca
    ja võtta ainult mõttekad dimensioonid või kaaluda välja olulised.
-   jätkuvalt mis point on päris selge pole. aga võibolla siin ka
    optimisatsioon: raudselt on mingid alad kus nendes dimensioonides on
    tühjus st pole kunst kui seal oleks, või oleks halb kunst (saaks
    proovida neid täita mingi noise piltidega vms et näidata millised
    seal ilmselt oleks?) või näiteks et mis ajastutel kus augud on? kas
    on mingid suunad kuhu kunstnikud lähevad (lisaks ajastusuundadele)
-   weighted earth mover's distance?
-   artiklis: peaks olema pigem r-precision (mitu n kunstnikku üldse
    võivad matchida, ja siis palju neist on top n'is) või mean
    reciprocal rank et kui kaugel esimesest match on. peaks võrdlema
    mingi pretrained state of the art asjaga, ja siis kokku panema mingi
    NN ja see asi. ja vaatama kas need dimensioonid kattuvad, kas oleks
    kasulik teha mingi principal component analysis sinna.
-   wikiarti asemel? <https://deepart.ust.hk/ART500K/art500k.html>
-   Point Yanilt: Artists are usually very broad in terms of
    experimentations and styles they work in. The problem is that they
    are acknowledged and recognised for a limited amount of works that
    tend to fall in a limited space of style
-   Küsimus Vejunelt: For example, do women produce more noisy art? Does
    the noisiness in art increase with time? Is the use of certain
    colours in art/area of the art piece/etc, related to the level of
    noisiness?
-   kas selles ruumis liikumises on ka mingi advection?

- kunsti-andmestik
The raw data for this paper was provided by Marcos Nadal Roberts and Alex Forsythe,
who have not given their permission to publish the data as part of this manuscript. This data was originally compiled for Marcos Nadal Roberts’s doctoral thesis, available at http://ibdigital.uib.cat/greenstone/collect/tesisUIB/index/assoc/TDX-0404.dir/TDX-0404108-112455.pdf. This data can be obtained from the corresponding author Alex Forsythe, email aof@aber.ac.uk (https://onlinelibrary.wiley.com/doi/abs/10.1348/000712610X498958) .


## meetings 
### kohtumine 05.02.2021.

-   Ok võibolla ainult kompress on ok, aga peaks ikkagi mõõtma täpsust.
    äkki mitte lihtsalt sarnasus, vaid kui saaks mingi wordneti moodi
    asja peal teha - nt mona lisa sarnane on mõni muu vinci, aga ka ok
    mõni popart koopia 500a hiljem.
-   wikiart on sesmõttes imelik, et mitte kunsti ajalugu vaid
    kunstiajaloolaste tehtud ajalugu.
-   ok mida veel kompressida: pealkirja pikkus/entroopia,
    värvikompleksus

### teine kohtumine 19.02

-   ühendada kunstnikud, vaadata kuidas nad selles ruumis liiguvad siis.
    kas edasitagasi, kuhugi edasi, mis on nurgad.
    kvantifitseerida/klastedada kuidagi trajektoore mitmedim ruumis,
    saaks võrrelda kunstnikke (normaliseerida aastad), perioode jms.

-   vaja rohkem kunstnikke - 10 liiga vähe, kui rohkem siis suurem pilt,
    lihtsam matchi leida ja ka modelleerida

-   reciprocal rant võibolla liiga karm (samas kui rohkem data saab vast
    parema)

-   proovida muid kaugusi, nt jensen, euclid -> cosine annab sama mis
    euclid aga 2d plottides näha et kõrvuti olevad punktid erineva
    skooriga, st vektori suund oleneb - aga siin vist pigem oleneb punkt
    eucl ruumis? või üldse ---> teha mingi classifier kuhu need pca
    skoorid sisse lähevad; Ahnert mainis support vector regressionit.
    või mingi cnn.

-   pmst tulevikus võiks filmide peale ka teha, film kui kunstnik
    (stseenid) või resisöörid

-   ja siis see instagrami generative art asi, kas saaks sisse panna ka?

-   artiklis peaks rõhutama kohe et mõõdame mingit abstraktset
    kompositsioonilist ja värvilist komplekssust, mitte semantilist - st
    võibolla mingi hull stoori seal taga aga suva - ja see tehniline
    kompl on ka estimate, st võibolla on kasutatud mingit väga keerulist
    aeganõudvat tehnikat või kallist materjali - ei tea, aga kui masin
    ei tea, siis suva näitusekülastaja ilmselt ka mitte.

-   aga vaja teha: alustada kõrgemast resolutsioonist ja teha igast
    transformatsioonist mitu variant, mitme erineva reso pealt (nt edge
    detection väga erinev), kui saab siis ka kvaliteedi pealt

-   juurde: kõik samad filtrid aga võtta välja keskelt kuldlõike ruut -
    ääred kohati raamid, ja nt kohati keskel mingi keeruline (või just
    monoliitne) asi, äärtes muu. võibolla mingid lõiked veel?

-   Tillmanni point kontseptuaalse komplekssuse kohta, picasso - huvitav
    kas vähemalt seda saaks, et teeks mingi resnet50ga sarnasuse, aga
    sama moodi sarnasuse erinevate transformatsioonide vahel - mingi
    edge detection variandis need kaks pulli oleks väga sarnased, seal
    dimensioonis on ühendus, näitaks et pole lambist uus pilt vaid
    mingit dimensiooni pidi seotud (umbes nagu see sõnatähenduste
    algoritmiline liikumine-laienemine, pole ka lambist vaid sujuvalt).
    "once a level of perfection was reached, it went in another
    direction towards the white blob"

### kolmas kohtumine 12.03.2021

-   liikujad vs hüppajad sammu pikkuse järgi? aga probleem et osadel
    kaks-kolm striimi, nt õli ja lihtsad joonistused ---> oot lahendus,
    teha dbscan ja kui on 2+ klastrit mille sees on ajaline
    dimensioon/pole üks periood, siis järelikult on paralleelsed
    stiilid.
-   klastrid stiili järgi, siis korrelleerida ajaga, kas korreleerub
    (klastri sees ja klastrid üldse)
-   või mingi network asi
-   proovida erinevad klasterdusi, ja siis vaadata kes need on kes ei
    klapi ühegi süsteemiga
-   ja tahavad mingit interaktiivset asja (aga S mingi 3d plotly ploti
    tegi; ekstra dimensioon vist palju ei anna aga lipikud ilmselt
    annaks)
-   ja et kõigi kunstnike peale sama plott
-   color complexity not perfect - if all browns vs if rainbow. could
    count better. või jäta üldse välja, see paletiplott on lõpus olemas.
-   teha maatriks: kus on iga pilt ja kõik dimensioonid, kõigi kunstnike
    kohta, vaadata kuidas muutub, aja järgi reas; aga saaks ka
    kunstnikud vs teised kunstnikud, korrelatsioon või JSD (pmst KL aga
    on metric); compressions vs compressions, kunstniku kaupa
-   saaks võrrelda kunstnikke, võrreldes neid viimaseid maatrikseid (mis
    omakorda annab maatriksi)
-   kompressiooni-näide: pildid x transformatsioonid, aga ruutudes pole
    mitte % vaid pildid, suurus \~ kui palju saab kompressida (aga kas
    pca või kompressionid otse) -> kas saaks ikkagi pca omasid kasutada,
    aga pilt võtta sellest tunnusest mille loading kõige suurem on? või
    sortida tunnused kuidagi pca kaudu?
-   või: aeg värvina, maatriksi read klasterdatud sarnasuse järgi,
    tulpades compressionid
-   outlierid ajas - tooks välja luuserid aga ka innovaatorid kes edukad
    olid, need kes ajast ees olid jms. ja palju see
    konsensusega/kunstiajalooga korreleerub?

### neljas kohtumine 26.03.2021 (Sebastiani polnud)

-   muusika+video ka
-   max tahaks wiki+cryto+turismipildid
-   maatriksil klasterdada sarnased, praegu need ribad on liiga kitsad;
    aga kuidagi peaks nii tegema, et eripärased välja paistaks, aga
    samas ka ei domineeriks. äkki see hbdscan, aga suuremad grupid
    laiemate ribadena.
-   see liikumine teha, ja tõenäosused kust kuhu liigutakse multidim
    ruumis.

### n kohtumine 12.05.2021

-   r2 juurde ka ennustustäpsus (mean accuracy vms)
-   peaks testima kunstimudelit normide peal, aga et äkki saaks ka
    normi/fraktalimudelit testima kunsti peal (kunstnike eristamine)
-   "different art historians have different PCAs in their minds" -
    could do pca on subset and see if they agree
-   see et kõik top PCd ei korrelleru olevat hea, kuidagi, et pole liiga
    obvious
-   Sebastian arvab et äkki pigem multi-svm kui cnn klassifikaatoriks,
    et äkki saaks sellega ruumi ka modelleerida, aga ma pole päris
    kindel kuidas. Max arvab et diffusion maps on parem kui pca... peaks
    vaatama. või mingi muu lihtne kaalumine vektoritele (lasso vms?) mis
    laseks kuidagi lihtsalt seda kunstnikutuvastust teha. pmst saaks
    vektorisarnasusega ka, kui kuidagi PCsid kaaluda saaks. Äkki
    dimensioonid millel on kõige suurem keskmine kaugus kunstnike
    paaride vahel st eristavad neid, ka need kaalud (treenituna eraldi
    seti peal) kasutada kaalumsieks testseti peal?
-   peaks vastama mitte (ainult) traditisioonilisele küsimusele, aga
    just mingile uuele asjale VÕI vastata suurel skaalal küsimusele mida
    on vastatud väiksel skaalal
-   võibolla see ruumis liikumine on hoopis järgmine artikkel
-   Tillmann: "It would show two types of artists I assume, the once who
    do something and stick with it (99% being unsuccessful) and just
    being lucky, and then the "workers" , who are actively exploring the
    space to find their niche. (And a third group jumping on the
    bandwagon)"

### kohtumine 04.06.2021

### kohtumine 19.07.2021

-   max tahab mingit persistent homology asja - põhineb
    täis-distantsi-maatriksil + filtreerimine

### kohtumine 26.07.2021

-   expansion ok to try to include
-   duchamp, mondrian, richter (try also picasso, georgia o'keeffe,
    kandinsky, turner) - figure 2/3; and also predict their closer ones
    (fig1 is workflow and big space)
-   new mad idea: do FFT and then run the full transform+compression
    stack. But log the magnitude. IM: "This is done by applying a strong
    Evaluate Log Transform to a Normalized 'magnitude'".
-   FFT outpurs square of x\*x where x is the WIDTH of the image! so
    aspect messes with things. rotate or normalize?
-   Max's plot idea: umap, but look at pcs. color spectrum to PCA param
    range, ump x\*y, and then 109 same umaps, but each plot is colored
    by each PC. like stamps. maybe appendix?
-   the mini matrices: either labels by year; or two matrices, 1 by time
    1 by cluster. need trees! and color by year. and/or style period.
    and try to order the tree by time.
-   Max: Ferdinand Hodler (clear phases and genres), Georgia O'Keefe
    (super-consistent chroma spectra), and Raphael (the reference point
    of peak-naturalness; also cf. "pre-raffaelites"), Artemisia
    Gentileschi (looks like Caravaggio but all paintings have a cut off
    head), Kandinski (clear gradient like Mondrian, and a
    differentiation of study/composition/improvisation, which we may
    spot or not; I typically do, but this is advanced, so if we can pick
    this up would be crazy good); Duchamp (versatility); Frank Stella

### kohtumine 16.08.2021

-   võiks ikkagi olla ports maatrikseid, aga siis mingid mõned näited ja
    üks suur näide kus on iga puuklastri peale mingi 5 näitepilti ka (ja
    siis lisas võibolla kõik pildid), nt et kui 4 klastrit siis 4x5
    pildid kõrval. ehk siis maatriks, puu, näited.
-   Sebastian: should be methods paper but hinting at certain
    application. but no groundbreaking art history changing thing.

### kohtumine 07.10.2021

-   time series asemel klasterda, vaata mitu klastri, ja siis seda
    lõigata. aga kuidas võrreldavaks teha?
-   pärast juurde ikkagi panna need ka millel aastat pole või hägune
    aasta. ja need trajektoorid pigem teha sarnasuse järgi, ja need
    maatriksid ka, lihtsalt kus pole aastat on hall ja suva. praegu on
    70k sees ainult aastaga.
-   

### kohtumine 10.11.2021

- matrices flip so it's top to bottom
- kappa or accuracy: put raw % in matrix but put null stright on/in the plot (not just caption). use 2 for paper.
- explorations: distros use style periods instead of centuries
- the comet: compare lesser known and more known. Matrisse, Modigliani, Duchamp
problem of moving window, but maybe fine
or: x same, but color on y axis, z-scored career so it's comparable. most artists have one big peak so more or less gaussian (cite the hot hand paper or whatever)

### kohtumine 01.04

new figure 1: all compressions, add mondian matrix but instead of the example image, and then all other by the same artist

fig2 maatriksid joonteks. mõned transformid ikkagi peale märkida või captionisse panne.

fig3 pealkirjad väiksemaks, fondid sama suureks
fig3 next to pc1 pc1, but highlight with horizontal lines. color hic by sales
hic to horizontal strip, white num
add inset with bubble/variable size tile map

fig4 
cezanne + cassat + kahlo
mondrian + rothko
whistler + chase
bierstadt

SA: alphabetical last name, relax filter to have more. make title font smaller, put outside box
SA: the color pixels, say how resize works


## september 2022

- koodis oli bug, pildi normaliseerimine kasutas ainult kõrgust, seega osa tulemusi on ilmselt jamad
 # newsize[[i]]=round(xy * sqrt(pixeltotal / (xy[i] * xy[i]))) # old, bug
 newsize[[i]]=round(xy * sqrt(pixeltotal / (xy[1] * xy[2])))
 
 - tuleks implementeerida see värvide arvu normaliseerimine, lihtsalt rgb + depth tundub ei töötanud
 - ja fixida imagemagicku multicore, et saaks normaalselt jooksutada.




## artikkel

-   peab ütlema et pole kunsti ajalugu, vaid kunstiajaloo ajalugu, st
    nagu korpus, näited; viita landscape paperit, seal juba jutustatud

-   täpsuse ploti peale random baseline joon

-   äkki saaks wikiarti ja nft'd võrrelda võttes prediction errori,
    confusion on sarnasus, saaks vaadata mis perioodi või stiiliga (siis
    vist peaks lda välja jätma)

-   Tillmann: while artistic photos are controlled by the artist,
    meaning every element is in there for a reason, tourist photos have
    many random elements in it

-   nüüd on plaan et pigem selline meetodiartikkel, kus erinevaid asju
    võrrelda, diakroonia ja sünkroonia ja erinevad andmed (või isegi
    kunst ja muusika, film ka)

-   kolmas plott peaks olema mingi suur kaardistus

-   louvre 50k ka juurde?

-   fookus oleks see boundedness, ja kuhu saab minna (mingi markovi
    ahela taoline asi teha, et kust kuhu tõenäoliselt minnakse, pmst
    \~advection), aga "valideerimiseks" see kunstnikutuvastaja, ja
    võrrelda nende deeplearning CNN meetoditega.

-   artiklis peaks mainima et nt valge ruut ja müraruut on mingis
    dimensioonis (värvidistributsioon) väga lähedal, aga see dimensioon
    kirjeldab vähem variatsiooni (praegu mingi 5%).

-   ja et semantikat pole sees - nt kui mingi vant joonistab kümnes eri
    stiilis kasse, siis pole sarnased; kui aga joonistab samas stiilis
    kass, kosmoselaeva ja veevirvenduse, siis on sarnased kõik.

-   color grading on probleem aga mis teha

-   kunstniku tööd kokku kui Manfred Eigeni quasispecies (pole samuti
    "õiget" prototüüpi keskel). maalid rohkem nagu bakterid mitte
    imetajad, kõik saavad omavahel geneetilist materjali jagada.
    horizontal meme transfer, pole päris nagu darwinian evo aga midagi
    sarnast. mis eristab neid kvasiliike (dali on äratuntav - miks?).
    kuidas see ruum on täidetud, kus on augud? (peaks välja mõtlema mis
    see analoogia annab samas) AGA samas saaks hinnata et kuidas need
    augud täituvad, mis juhtub kui auk kuskil on. sama mis sügismoe
    ennustamine.

-   avutada kui palju ruumist (valge ruudu ja müra vahel) on täidetud -
    arvutada kõik võimalikud permutatsioonid pikslikombodest (võibolla
    peab värve vähendama/kvantiseerima või mustvalgeks), ja mis density
    on.

-   kas peaks mingi crowdsourcingu ka tegema (või küsima kunstnikelt?)
    et kas see komplekssus klapib - näiteks paarikaupa pildid, ja siis
    vaadata mis dimensioonid paremini korreleeruvad järjestusega mis
    sellest tekib.

-   plot niimoodi teha, et minimeerida pc1 (ja kui saab 2), st
    nullilähedased, ja siis näidata pilte, kus nad teiste komponentide
    peal on.

-   see model lite, kus ainult paar transformi, see on rohkem nagu aju,
    pca on nagu retiina

-   2 questions in art history, what can i see (artist, era, content),
    where does it come from (evolution, why)

### näited

-   mondrian, pollock, turner (pidavat huvitav trajektoor olla),
-   teha mitu pc plotti ja panna nagu slaidi üks teise järele, tagumised
    väiksemad (läbipaistvad?), nagu plaadid, nurga alt vaadatuna.
-   max arvab et äkki vähipildid ja nooleotsad äkki ka (Ben Marwick)
-   ee aga gen kunst? seal oleks ju teada kaua masin töötab või kui pikk
    kood on
-   Marcel Duchamp
-   gerhart richter
-   kuhugi võibolla hiljem: teha poolläbipaistvad komposiidid
    naabruskondadest
-   ploti-idee: see suur kaart teha nii et iga pilt on mingi 1 või 4
    pikslit (geom_image, pildid tehtud väikseks; või kui 1px siis
    lihtsalt custom värv, mis omakorda tuleb pildi kõige
    sagedasemast/quantized värvist), aga nurkadest ja keskelt on
    "zoomitud" sisse mingid naabruskonnad, noolega paneelidena. siis
    näha, et sarnased on kõrvuti, samas vähem hägu. või lihtsalt mingid
    2-4x pilti nurkades, nt 3x3 üle kaardi, et annab aimu mislaadi
    kuskil äärtes on.

### viidata:

#### tehniline

- https://twitter.com/nataliewildlife/status/1491437546584567808  From Beethoven to Beyoncé: Do changing aesthetic cultures amount to cumulative cultural evolution?

- - !!! Complexity and Aesthetics in Generative and Evolutionary Art - võrdlevad eri meetodeid  https://arxiv.org/pdf/2201.01470.pdf

-   väga sarnane!! võrdlevad pilt vs blurr-pilt: Multiscale structural complexity of natural patterns; https://www.pnas.org/content/117/48/30241

For Lévy-flights in 3D space see:
González, M., Hidalgo, C. & Barabási, AL. Understanding individual human mobility patterns. Nature 453, 779–782 (2008). https://doi.org/10.1038/nature06958 [references 9-13, including the following]
Viswanathan, G. M. et al. Lévy flight search patterns of wandering albatrosses. Nature 381, 413–415 (1996) https://www.nature.com/articles/381413a0.pdf

For an attempt to use the notion of Lévy flights in Cultural Analytics (philosophical texts) see:
Thompson, William HW, Zachary Wojtowicz, and Simon DeDeo. "Lévy Flights of the Collective Imagination." arXiv preprint arXiv:1812.04013 (2018). https://arxiv.org/pdf/1812.04013.pdf
For Exploration vs Exploitation in Art History see:
Liu, L., Dehmamy, N., Chown, J. et al. Understanding the onset of hot streaks across artistic, cultural, and scientific careers. Nat Commun 12, 5392 (2021). https://doi.org/10.1038/s41467-021-25477-8 [This is the follow-up of a Nature paper using the same data!]
The latter uses the art500k dataset and uses AlexNet. 

-   võrdluseks tuvastustäpsus: Ceci n'est pas une pipe: A Deep
    Convolutional Network for Fine-art Paintings Classification
    <http://web.fsktm.um.edu.my/~cschan/doc/ICIP2016.pdf>

-   parem võrdlus isegi on see art500k oma: DeepArt: Learning Joint
    Representations of Visual Arts

-   "the shape of time" lugeda?

-   (2013) O. Morin, "[How portraits turned their eyes upon us: Visual
    preferences and demographic turn-over in cultural
    evolution](https://sites.google.com/site/sitedoliviermorin/morin-2013.pdf?attredirects=0)".
    Evolution & Human Behavior (34), 222-229

-   Stefano Balietti, Matjaz Perc - võimalikud reviewerid, peaks
    viitama, eriti hinnangute osas. teine olla vähe imelik/pätt.

-   Characterizing Variability in Shared Meaning through Millions of
    Sketches
    [\<https://twitter.com/PsyArXivBot/status/1384600278339629058>](https://twitter.com/PsyArXivBot/status/1384600278339629058){.uri} -
    kasutavad Hausdorff distance, mingi pikslite earth mover pmst.

-   **A simple method for estimating the fractal dimension from digital
    images: The compression dimension**
    <https://www.sciencedirect.com/science/article/abs/pii/S0960077916302399>
    ütleb et png jms compression korrelleerub fractal dimensioniga
    (mustvalge peal)

-   eriti kui kasutada "compression ensembles", peaks viitama
    <https://www.pnas.org/content/pnas/106/18/7345.full.pdf> neil ka
    mingid ensemblid aga rohkem nagu üldisemas "palju statistikuid"
    tähenduses. aga samas ka visual perception.

-   nassir

-   M3 measure from "Measuring Colourfulness in Natural Images"

-   Li et al. DOI 10.3389/fpls.2018.00553, which uses a different method
    to analyze the "Leaf Morphospace" of 180k plant leafs. ---->aga
    võibolla ka ise sama seti peal teha.

#### ajalugu

- lotman structure of artistic text.
- language of art: lessing, novalis, blake, wackenroder, humboldt
- Lotman structure of artistic text: When we deal with the visual (spatial) arts, this becomes especially clear: the rules for representing the multi-dimensional and limitless space of reality within the limited, two-dimensional space of a painting become its specific language. For example, the laws of perspective as a means of representing three-dimensional objects in a two-dimensional image in a painting become one of the basic markers of the modeling system.
- Kolmogorov 1964: The majority of examples in works on cybernetics concerning the computer modeling of processes of artistic creation are strikingly primitive (the compilation of melodies from four or five note segments based on twenty or thirty melodies fed into the computer, and so on). In non-cybernetic literature, the formal analysis of artistic creation has long been on ahigh level. Information theory and cybernetics could make a large contribution to these studies. But real progress in this direction demands that cyberneticians take a greater interest in the humanities and learn more about them. A. M. Kolmogorov, "Zizn' i rnyslenie kak osobye formy suscestvovanija materii," 0 suscnosti iizni (Moscow, 1964) p. 54.

-   birkhoff 1933

    -   Who, for instance, would attempt to compare a vase with a
        melody? In fact, for comparison to be possible, such classes
        must be severely restricted. Thus it is futile to compare a
        painting in oils with one in water colors, except indirectly, by
        the comparison of each with the best examples of its type; to be
        sure, the two paintings might be compared, in respect to
        composition alone, by means of photographic reproduction.

    -   M is applicable only if the class of objects is so restricted
        that direct intuitive comparison of the different objects
        becomes possible, in which case the arrangement in order of
        aesthetic measure represents the aesthetic judgment of an
        idealized 'normal observer.

-   Max ütleb vt mingi continuity in the annealing of images - a guuglis
    pole...?

-   **Birkhoff's aesthetics, Arnheim's entropy. Some remarks on
    complexity and fuzzy entropy in arts**
    <https://www.tandfonline.com/doi/abs/10.1080/18756891.2015.1113745?journalCode=tcis20>

-   Predicting beauty: Fractal dimension and visual complexity in art

    -   fractal dim siit: Klinkenberg B. (1994) - . Mathematical
        Geology, vol. 26, n° 1. doi: 10.1007/BF02065874

-   Birkhoff Revisited: Beauty as a Function of Effect and Means

-   Rigau, Jaume, Miquel Feixas, and Mateu Sbert. "Conceptualizing
    Birkhoff's Aesthetic Measure Using Shannon Entropy and Kolmogorov
    Complexity." *Computational Aesthetics*. 2007

-   Algorithms seem to offer the most promising development in the
    measurement of

    visual complexity. Lempel and Ziv (1976) developed the earliest
    model. Their algorithm

    for complexity was based on the smallest computer program required
    to store/produce

    an image and it is this algorithm that is the basis for the
    compression techniques we

    use today. Recent developments in the analysis of visual complexity
    have applied such

    algorithms in the study of visual complexity (Donderi, 2006b;
    Forsythe et al., 2008).

-   Mingi local statistical complexity ja normalized permutation
    entropy: **History of art paintings through the lens of entropy and
    complexity**
    [\<https://www.pnas.org/content/115/37/E8585>](https://www.pnas.org/content/115/37/E8585#sec-7)
    "We present numerical scales that map well to canonical concepts in
    art history and reveal a historical and measurable evolutionary
    trend in visual arts"

    -   "Nevertheless, the achieved accuracy is quite modest for
        practical applications. Indeed, there are other approaches that
        are more accurate. For instance, Zujovic et al. (65) achieved
        accuracies of ∼70% in a classification task with 353 paintings
        from five styles, and Argarwal et al. (66) reported an accuracy
        of ∼60% in a classification task with 3,000 paintings from 10
        styles. However, our results cannot be directly compared with
        those works, since they use a much smaller dataset with fewer
        styles and several image features, while our predictions are
        based only on two features. Our approach represents a severe
        dimensionality reduction, since images with roughly 1 million
        pixels are represented by two numbers related to the local
        ordering of the image pixels. In this context, an accuracy of
        18% in a classification with 20 styles and more than 100,000
        artworks is not negligible. Moreover, the local nature of H and
        C makes these complexity measures very fast, easy to
        parallelize, and scalable from the computational point of view.
        Thus, in addition to showing that the complexity--entropy plane
        encodes important information about the artistic styles, we
        believe that the values of H and C, combined with other image
        features, are likely to provide better classification scores."

-   Morin ja Miton, vektoriseerimine+zip et tähegrafeemide komplekssust
    hinnata
    <https://www.sciencedirect.com/science/article/pii/S0010027721001906>

-   Miton et al **A Forward Bias in Human Profile-Oriented Portraits**
    <https://onlinelibrary.wiley.com/doi/full/10.1111/cogs.12866> (väike
    valim, vist käsitsi)

-   **Mapping the NFT revolution: market trends, trade networks and
    visual features** <https://arxiv.org/abs/2106.00647>

-   Tran, Entropy trade-offs in artistic design: A case study of Tamil
    kolam <http://dx.doi.org/10.1017/ehs.2021.14>

-   **Entropy and complexity unveil the landscape of memes evolution**
    <https://arxiv.org/abs/2105.12376> - sama meetod mis **History of
    art paintings through the lens of entropy and complexity**

-   keegi Ahmed Elgammal kes ei viitsind enam NNidega jännata sest ei
    saa tõlgendada, aga pole seda vist kirja pannud

-   alexnet on tõlgendatav(am) vms

-   chinese ink aesthetics
    <https://www.researchgate.net/publication/347631469_Inkthetics_A_Comprehensive_Computational_Model_for_Aesthetic_Evaluation_of_Chinese_Ink_Paintings>

-   **Quantifying the compressibility of complex networks**
    <https://www.pnas.org/content/118/32/e2023473118> Future work could
    directly address this hypothesis by investigating whether real-world
    networks, from language and music to protein interactions and the
    internet, have evolved over time to become more compressible. From a
    complementary perspective, one could develop methods for designing
    artificial networks that are optimally compressible. What might such
    optimally compressible networks look like? And how close to optimal
    are the networks that we observe in nature and society?

-   Entropy and complexity unveil the landscape of memes evolution (like Sigaki but memes) https://www.nature.com/articles/s41598-021-99468-6



#### eval

-   forsythe predicting beauty, had eval set
-   
-   fraktalid kui test case: **Can Vision Transformers Learn without
    Natural Images?**
    [\<https://arxiv.org/abs/2103.13023>](https://arxiv.org/abs/2103.13023){.uri}
-   ja siit saaks 400 näidet
    [\<https://psyarxiv.com/uy9hk/>](https://psyarxiv.com/uy9hk/){.uri} -
    ütlevad ka et "data compression rate of fractal image files was
    positively correlated with the subjective rating of complexity".
    Standardized database of 400 complex abstract fractals Rebecca
    Ovalle-FresaSarah Di PietroThomas ReberEleonora BalbiNicolas Rothen
-   gif compression correlates with human: Examining visual complexity
    and its influence on perceived duration
-   spanish picpsy
    <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7489540/> "The bank
    has also been reproduced in a colored drawings version but the norms
    of the present study are collected only for line drawings and
    photographs" ++ sarnaseid on muudest keeltest ka
    <https://sites.google.com/site/bosstimuli/other-sets-and-norms> ja
    <https://www.cogsci.nl/stimulus-sets>
-   üritada kokku panna ajaloolised klastrid/stiilid selle asjaga, äkki
    mingi max likelyhood



### reviewers

Both Dashun Wang and Simon DeDeo would be excellent reviewers for our paper we could suggest. If we can claim improvement over the Dashung Wang paper, other journals than PNAS may be open. Simon DeDeo is established as a reviewer in PNAS.  Another good reviewer would be Matjaz Perc.







# Hull kunstimõte

Mar --- Imgen ja iterated learning?
Random additional idea: if the comparison is between 2 conditions, human artists and human non-artists (in this new world where everybody can be an artist), and the chain is
seed image/seed text -> human1 adjusts text > txt2img, new image > human2 adjusts text >...
Then another 3rd condition could actually be machine, in the form of the CLIP interrogator
seed image/seed text ->  interrogator adjusts text > txt2img, new text > interrogator adjusts text >...
While the serious focus could still be on the 2 human groups, this could add the comparison of an artificial noisy channel, sort of a "what happens if we leave the machines alone with themselves".
+Note that for the human conditions, the instructions would need to be very carefully worded - you don't want them doing random stuff, but you also don't want them to just look at the incoming text description and say "yeah good enough" and not adjust it, otherwise they might stay stuck in a sort of a local maximum. Like if seed is green chair img and text is "green chair", they would prob say yeah that's good enough.
So - and this will be an answer to some hypothesis about creativity in the face of informative need - you might  instruct them to be maximally descriptive within the length constraint of the prompt. This will force them to throw out less informative words and put it better descriptions, which will give the txt2img something to work with. This goes nicely also with theories of human communication, that we aim to be maximally informative but at the same time maximally efficient/simple, which leads to the informative-simple optimal front witnessed across languages in numerous studies, incl mine where we showed experimentally it's modulated by communicative need, i.e. whether you lean more towards information accuracy (more complexity) or being fast (but less accurate).
However, if you want to construct some hypothesis concerning artists vs nonartists and just creativity as such, then it would need a different formulation of instructions (e.g. "you will see an image and another participant will draw a new image based on your description of it, please describe it so the new art piece would be as artistic/beautiful/aesthetic as the image you are seeing" or something; prompt length should probably still be constrained).

- "Multi-label iterated learning for image classification with label ambiguity" viitavad Simonit. https://arxiv.org/pdf/2111.12172.pdf
- "ANALYZING DIFFUSION AS SERIAL REPRODUCTION" ka viitavad iterated learningut
- SINE: SINgle Image Editing with Text-to-Image Diffusion Models
- "Datasets That Are Not: Evolving Novelty Through Sparsity and Iterated Learning" mingi poster

Tillmann. Saaks itereerida stable diffusion ja clip interrogator kordamööda. peaks fikseerima nii palju kui saab, aga saaks varieerida/võrrelda:
- erinevad sisendpildid/teemad
- temperatuur mada/kõrge
- komplekssus madal/kõrge. valge ruut ja müra. saaks ka kaks conditionit teha kus sarnased pildid aga lihtne vs keeruline a al tool; omavahel sarnase komplekssusega.


# Poliitilised keelemuutused

- ETAG tahab 500 sõna kirjeldust kui raha kasutamine üle küsida, et kuidas projekti eesmärkidega kooskõlas, mis tulemused.

- märksõnad https://docs.google.com/document/d/1i-1BHE47lazV-asZ_3Du-pCmLhn5CMFtOdgQTQd5J-4/edit

- aga: võiks teha vene-vene keel vs balti-vene keel ja/või ukraina vene-keel, uudistes või sotsmeedias, praegu.

## tehniline

- pmst võiks ka teha klassifitseerija mille täpsus omakorda näiteks jutu erinevust. või siis mingi struct topic model mis ennustaks poolust, pmst sarnane aga saaks vaadata mis teemad lahknevad.

- !! ka tvitter ja roberta Slangvolution: A Causal Analysis of Semantic Change and Frequency Dynamics in Slang https://arxiv.org/pdf/2203.04651.pdf

- hamilton ütleb et OP ja vector initialization suht sama, Dominik et vi on jama ja sõltub sagedusest https://aclanthology.org/P19-1072.pdf, mul nagu tundus ok ja vastupidi OP jama. samas: we length-normalize and mean-center A and B in a pre-processing step (Artetxe et al., 2017) (selles järjekorras,  normalize to unit length ridade peal, ja iga tulp miinus keskmine)

-   kas sama saaks teha nüüd bmmg korpusega?

-   äkki mitte ainult fox vs cnn järgijad, võibolla ka mingi üldine
    neutraalne keel kolmandaks, võrdluspunktiks, nt wikipedia embeddings
    vms. mingi delta nende vahel võrdluseks

-   Grievel pole aega aga ütles et disaini kohti võib küsida lühidalt
    ikka.

-   kas reddit või twitter. muud lõhenenud maad ka? siis oleks keele
    rääkijaid vaja juurde tõlgendama.

-   kindlasti see multiword unit vahesamm ka, sest paljud on
    mitmesõnalised, nt deep_state

-   võibolla peaks nüüd semevali peal ära testima, kas see LSA meetod on
    ikka ok.

-   plot: \|divergent meaning \| \| \| \|same \| \|meaning \|
    ------------------------- left \<\<\<\< 0 >\>\> right ja siis
    võrdluseks näited, et see x erinevus on sama palju erinevus y ja z
    vahel, mis on migid arusaadavad sõnad. võibolla paralleelselt lausa
    plott alla, kus mingid näited.

-   evaluatsioon: võtta võrdluseks midagi neutraalset nagu wikipedia, ja
    siis võtta välja fraasid-sõnad mis polaarseid korpusi eristavad
    wikist sageduste poolest, ja siis omakorda nende abil
    klassifitseerida/klasterdada - siis pole teemade erinevus nii
    oluline, loodetavasti kallutatus tuleb välja, ja kui omakorda
    sellest tuleb vasak-parem skaala mis on \~sama mis allsides, siis
    järelikult allsides on ok.

-   

## mida vaja on:

-   kasutajad: välja filtreerida enamvähem aktiivsed, mõlemast rühmast
-   tõmmata nende timelined regulaarselt
-   twitter academic api: rtweet veel ei toeta, aga:
    <https://github.com/cjbarrie/academictwitteR>

## koosolekud
### 03.03.2021

-   tegeleb hansardiga CAIL interaction osas, information rate
    erinevates kõnezanrites+vanus
-   edasi: twitter, aga kas kõik->filter või eelmine
    uudisteaccountid->järgijad?
-   ikkagi siis mitme uudisteaccounti kaupa, rühmitada, ja
    kõigi-järgijad välja
    
### 04.11.2021

- teha task; koguda dog whistle'id
- küsida lauses kas on erinev tähendus, ja siis üksiti et kui subjektiivne

### 07.04.2022

- kasutame DURELit pmst
- mina tekitan mudeli(te)st kandidaadid ja sämplin laused, nii erinevad kui sarnased.
- C teeb interface'i
- turk, burn in oleks mingi 5 lauset kus on 0 ja 100 kontrollid sees et aimu saaks; vahepeal ka kontroll-laused
- taustal vaataks mis vene andmeid saaks

### mai 2022

TODO
- filter tweets for examples of: 50-250 char range, target occurs 1-2, same POS, same form (allowing for inflection)
- see how many sentences available actually
- 20 per side, allows for 20 leftright comparisons and 10 & 10 sameside comparisons
- render sentences as images, name as word_type [left, right, sanity]
- put in side into id so db can combine
- json with {"sentence":"xxx", "targetword":"xx", "side":"y", "id":"z", "image":"word_side_z.jpeg"}
- unique sanity words, easier?

Setup
- minimal 10, max 100
- 30 cents for 10;  2 cents per extra example
- or blocks of 200-250 per person, 10$ per person. ~500-600$
- save on overhead, instead large n hits post <9 over and over
- 32*3*20 = 1920

Sanity check sentences (complex but same meaning of target)
- pops up after every n real examples, more at first, less later
- check sd of ratings
- check reaction time





## viidata


- The Language of Russian Fake Stories: A Corpus-Based Study of the Topical Change in the Viral Disinformation

- öelda et me võtsime skin tone modifieri maha sest vähe andmeid, aga viidata alexit.
- pmst jälle see LIWC sentiment asi, aga UK twitter: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0197002

- "Phraseology and imagery in UK public health agency COVID-19 tweets" corpus of all tweets sent by UK public health agencies during the first 11 months of the pandemic && "The Twittering Presidents An analysis of tweets from @BarackObama and @realDonaldTrump" - näide sämplimisest, et institutsiooni või inimese kaupa.

- Altmann et al (2011) Niche as a determinant of word fate in online groups vt mis lõpus on
- https://nejlt.ep.liu.se/article/view/3478 Kutuzov jt, analüüsivad bertitaolisi, et on probleeme, saab viidata et keerulisem.
- Grieve uus twitteriartikkel https://arxiv.org/abs/2208.07649

- Computational analysis of 140 years of US political speeches reveals more positive but increasingly polarized framing of immigration. Dallas Card 
- vt Jisu Kim, Carolina Coimbra
- Aparna Ananthasubramaniam, diffusion of new words, twitter
- Quantifying partisan news diets in Web and TV audiences https://www.science.org/doi/10.1126/sciadv.abn0083
- Distinguishing In-Groups and Onlookers by Language Use https://aclanthology.org/2022.wassa-1.15/
- Asymmetrical perceptions of partisan political bots https://doi.org/10.1177/1461444820942744

- Fanning the Flames of Hate: Social Media and Hate Crime  https://doi.org/10.1093/jeea/jvaa045

- vaja eksperimente: Reconsidering evidence of moral contagion in online social networks https://www.nature.com/articles/s41562-021-01133-5
- laste polariseerumine: Learning to Dislike Your Opponents: Political Socialization in the Era of Polarization
- The Political Landscape of the U.S. Twitterverse https://osf.io/w98ms/
- Uus: The manifold effects of partisan media on viewers’ beliefs and attitudes: A field experiment with Fox News viewers  David Broockman Joshua Kalla

- https://arxiv.org/abs/2204.04066 "Gettr-ing" Deep Insights from the Social Network Gettr

- konvekalt: Tvitteri artikkel https://doi.org/10.1073/pnas.2025334119 Pnas polarization phase transitions       https://doi.org/10.1073/pnas.2102144118   Private pol comm https://doi.org/10.1093/ijpor/edab033

- Dialectometric analysis of language variation in Twitter https://aclanthology.org/W17-1202/

- Partisan Blocking: Biased Responses to Shared Misinformation Contribute to Network Polarization on Social Media Johannes Kaiser, Cristian Vaccari, Andrew Chadwick Journal of Communication, https://doi.org/10.1093/joc/jqac002

-  Mila soovitas, ka twitteri peal midagi: Longhi 2021. Mapping information and identifying disinformation based on digital humanities methods: From accuracy to plasticity.

- https://psyarxiv.com/tp93r/  twitteri pealt, "Political Resources and Online Political Hostility: How and Why Hostility Is More Prevalent Among the Resourceful" et pole mingi lollide massi värk, jama tekitavad pigem haritud.

-  sarnane allsidesile: https://twitter-app.mpi-sws.org/media-bias-monitor/index.php
- see ground news, agregeerib allsides jms andmestikud, saab küsid twitteri accountide kohta, ja esitab uudiste juures bias meetrikut
- Peak Polarization? The Rise of Partisan-Ideological Consistency and its Consequences Alan I. Abramowitz (konverentsi pikem artikkel/abstrakt ainult veel)

-   pmst sarnane aga grammar, ja tavakorpus: Variation-Based Distance and Similarity
    Modeling: A Case Study in World Englishes https://www.frontiersin.org/articles/10.3389/frai.2019.00023/full
-   Covert Hate Speech: White Nationalists and Dog Whistle Communication
    on Twitter
    <https://link.springer.com/chapter/10.1007/978-3-030-41421-4_7>
-   An automated pipeline for the discovery of conspiracy and conspiracy
    theory narrative frameworks: Bridgegate, Pizzagate and storytelling
    on the web
    <https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0233879>
-   pole ainult social media echo chambers:
    <https://www.nature.com/articles/s41562-021-01066-z>
-   "Shifting attention to accuracy can reduce misinformation online" https://www.nature.com/articles/s41586-021-03344-2 https://twitter.com/DG_Rand/status/1372217700626411527 ka päris
    huvitav, tegid kasuliku kokkamisboti ja siis küsisid kasutajatelt et
    hei davai kas viitsid teha mu küsitlust. natuke sneaki aga näe
    töötas.
-   Visualizing Media Bias through Twitter - ka jagasid gruppideks,
    kolmas center ka
-   "Computational social science" Lazer et al, seal olevat mingi hea plot.
-   Bruno con Calvis PLOS ONE english spanish twitter
-   Duncan Watts at netsci 2020 using Nielsen (tv thing) data
-   vt
    <http://bostonreview.net/politics-philosophy-religion/c-thi-nguyen-polarization-or-propaganda> - pole akadeemiline
    
-   Kivelä et al twitter polarization https://www.sciencedirect.com/science/article/pii/S0959378021001278 (topikud hashtagide järgi)
-   vt <https://twitter.com/HelgeGiese> polarization midagi
-   **Out-group animosity drives engagement on social media** ka
    twitter, jälitasid poliitikuid, uudiseid jms
    <https://www.pnas.org/content/118/26/e2024292118>
-   pmst kõik need: <https://www.polarizationlab.com/current-research>
-   mingi jutt siin:
    <https://www.newyorker.com/magazine/2021/07/05/in-a-divided-country-communal-living-redefines-togetherness>
-   The Psychology of Online Political Hostility: A Comprehensive,
    Cross-National Test of the Mismatch Hypothesis
    <https://psyarxiv.com/hwb83/>
-   vt mingi Divided They Blog, hea plott, nüüd sama
-   meetod aga case studies ka : Partisan Differences in word usage:
    Rodriguez, Spirling and Stewart (2021)
    <https://github.com/prodriguezsosa/EmbeddingRegression/blob/main/Paper/RodriguezSpirlingStewart_EmbeddingRegression.pdf>
- samad tüübid aga mturk peal sõnade pakkumise katse, dem vs repub Partisan Representations: Partisan Differences in Semantic Representations and their Role in Attitude Judgments https://cogsci.mindmodeling.org/2018/papers/0102/index.html
-   Alexi emoij artiklid <https://arxiv.org/pdf/2105.00846.pdf>
- mingi comp mudel aga tvitter https://www.pnas.org/content/118/50/e2102147118 vt teisi samast editionist siit https://environment.princeton.edu/news/like-a-natural-system-democracy-faces-collapse-as-polarization-leads-to-loss-of-diversity/

## dogwhistles

-   intercity, bush wonder making, big pharma etc. sarnane slurriele,
    aga kavalamad. kas saaks suht lihtsalt tuvastada, kui võrrelda
    embeddinguid ja leida sõnad/fraasid mis on erinevate tähendustega,
    aga siis mingi signaal veel. need on sõnad mis sobivad konteksti,
    aga gruppide jaoks erinev tähendus, eriti kui kõnelejaga mingi
    assotsiatsioon.

-   vt Robert Henderson (Arizona) ja Elin McCready - pärast talki
    arutati et näe keegi võiks tvitterit vaadata, aga samas et mis teha
    hate-followeridega (võibolla peaks ikkagi rohkemate accountide kaudu
    profileerima kasutajaid?);

-   Robert Henderson (w Elin McCready), has a number of papers:
    <https://www.rhenderson.net/papers.html>

-   Gabriel Weimann - Digital Dog Whistles: The New Online Language
    of Extremism

-   Prashanth Bhat Ofra Klein - Covert hate speech: white
    nationalists and dog whistle communication on Twitter

-   Jennifer Saul - Dogwhistles, Political Manipulation and
    Philosophy of Language
    <https://core.ac.uk/download/pdf/131204314.pdf>

-   Mathilda Åkerlund - Dog whistling far-right code words: the case
    of 'culture enricher' on the Swedish web

## artikkel

-   network plot kus on näha et kaks sämplit on eraldiseisvad; kummagi
    keskmes on vastavad ankru-accountid.
-   kindlasti allsides omanikud jms ära seletada, ja öelda et ok pole
    ideaalne aga mingi tõenäosus.
- semantika: kui tahta bertiga, siis pmst vist? nii saaks fraaside vektoreid ka, kui tokenizer tühikut ära ei söö: https://towardsdatascience.com/3-types-of-contextualized-word-embeddings-from-bert-using-transfer-learning-81fcefe3fe6d

## kohtumine 19.07.2021

-   pull larger, 1000 tweets, but take only 200 top ranked tweets by
    likes or tweets with min n likes. prob not last, common people don't
    have many likes.
-   personal influence is mean likes/rt, or how fast they get to n likes
-   polarized language/words \~ who they follow + how influential they
    are (see dunking on outgroups paper)
-   predict polarization - as classification problem. train+test! sest
    muidu circular
-   keep more distance: hard left vs lean+hard right, and follows min 2
    on their side, and nothing on the other/between.
-   get location if possible, maybe use in classifier to show
    polarization model is better than just geo
-   dog whistles - see how much overlaps with existing
-   või hoopis see
    <https://www.journalism.org/2020/01/24/u-s-media-polarization-and-the-2020-election-a-nation-divided/>
-   Ma vahepeal kaevandan tweetid, C kirjutab abstrakti ja teeb lit
    review.
-   peaks kasutama doc2vec, kus user=doc, siis saaks kaardistada kõik
    kasutajad umapiga, värv külge, ja näidata et klasterduvad. ja siis
    sealt featurid ja klassifitseerimine.

## dominik ja nikolai, 04.10.2021

-   should probably annotate some testset.
-   
-   frequency -> apparently doesn't correlate in token embeddings
-   deepmistake needs word and \~50-100 pairs of sentences, slow.
    glossreader might be more feasible
-   Nikolai says they can run my testset if I generate on
-   või siis see, pmst glove
    <https://aclanthology.org/2020.semeval-1.25/>
-   a miks mitte LSA lihtsalt? -> seda ja glove sagedus tundub mõjutab





# Tasakaalustatus, aspect based sentiment analysis, stance, etc. Mark.

- kas berti saaks tuunida klassifitseerima korraga kahte asja, asjaolu ja stance (või see ongi aspect-based sentiment?). või mingi üldine poolt-vastu klassifitseerija üldise sentimendi asemel?
- või kas nüüd saaks midagi chatGPT laadset kasutada, et lihtsalt küsida et davai kas lause poolt või vastu? samas see jookseb pilves, kallis, ja kui ise jooksutada siis võimsat masinavärki vist vaja. Isegi 6B GPT-J võtab "48GB of CPU RAM to just load the model".

## viidata

- On the current state of reproducibility and reporting of uncertainty for Aspect-based Sentiment Analysis
- One Word, Two Sides: Traces of Stance in Contextualized Word Representations https://aclanthology.org/2022.coling-1.347.pdf






# Võimalik cudan position paper

- the sum or the thing that is more than the sum of the parts of cudan
- what is cultural data anyway?
- methods substance actors products

- cda on jõnks multi- ja interdistsiplinaarsem kui dh. lisaks hõlmab (comp) soc sci.
- digiteerimine jms teenused pole eesmärk iseenesest (nagu dh). ei eelda et on digiteeritud, aga fookus on analüüsil (isegi kui eeldab korjamist)
- kultuur kui (kompleksne) süsteem
- teised alused seega.
- what about korpusepõhised vms big data keeleuuringud? ilmselt ok, cda on interdistsiplinaarsem.

- Required: 
    - reasoning why this perspective exists 
    - empirical research or strong theoretical reasoning why CDA is a thing that is distinct or needed
    - lit review on things that we consider CDA (and possibly things we don't)
    - the actual perspective, what's the gap, what are the unsolved challenges, suggest program
    - where to submit this? depends on intended audience. lit review for new, conversion for old, invitation to join.
    - do actual science of science work and map out the adjacent landscape.
    - goal: is cda a recurrent umberella for people coming together from lit, lang, socsci, compsci --- or is cda meant to become a new, strictly interdisciplinary field with departments and curricula, that subsumes everything this is not traditional monodisciplinary strictly qualitative humanities --- and therefore is meant to become a monolithic discipline in the process. latter would require defining gaps that can't be filled/answered by current fields nor temporary umberella groups.
    - should make a plausible claim that if we train those people, then they can have a career in industry, that these people are broadly useful, not just academics. like data science or information science but cultur and soc.

    
- viidata
    - Hartley, John (2009) From cultural studies to cultural science (kvant/comp osas positiivne kuigi mitte metsikult tugevalt)
    
    


# Teiste tegemised

## Max

-   see mingi asi kus on värv ja jooned kvantifitseeritud - kui need
    taandada 2-3 faktori peale, siis saaks teha multi-label ennustava
    mudeli (nt random forest), mis näitaks ära kui hästi need
    etableerunud zanre ennustavad. Lisaks juurde see wikiart emotsiooni
    hinded, sama wikiart, saaks kokku viia. ja üldine (gif) komplekssus
    ka juurde. Kas see oleks midagi huvitavat?

## Yan

- Idee 21.07.2022: pmst võiks eksperimenteerida, kui saaks eemale abstraheerida sellest deitingu paradigmast ja vaadata lihtsalt enese-representatsiooni. Kuidagi tuleks lahti saada subjektiivsest atraktiivsusest. Nt lasta inimestel valida mingid (väga abstraktsed/lihtsad) profiilipildid, lasta svaipida, ja siis lasta muuta, vaadata kas muudavad. Või siis "matchida" neid, aga 2 konditsiooni, ühes matchib endasugustega (pildid koosnevad mingitest võrreldavatest ühikutest), teises teistsugusega, vaadata kas muudavad käitumist. Kas kuidagi saaks seletada kust need kaladega vennad tulevad kõik...? Ilmselt mitte.

- kui kasutada NN ennustuse skoore, siis peaks viitama https://arxiv.org/pdf/1706.04599.pdf - et need on liiga enesekindlad, aga samas siin oleks ok, sest võrdlus mudeli sees.
- saaks mingi ploti nt, kus on M-skoor ühel ja F-skoor teisel teljel, ilmselt siis maastikupildid oleks mõlemad 0,0 (kui neid skoore nii saab).

-   ok kui tahta eksperimenti, kas üks variant oleks lasta inimestel
    valida mingite avataride hulgast pildid (nt arvutigenereeritud või
    stock photos), ja siis mingid meemilaadsed, ja tekst (kas ise
    kirjutada või anda variandid) ja siis siis võrrelda, mislaadi
    inimesed mida valivad enda "profiiliks". ilmselt siin mingi
    atraktiivsus mängib rolli, aga sellega peab kuradi ettevaatlik
    olema, igatpidi õrn teema.

-   üks juhendaja peaks olema eksperimentaalne (ideaalselt
    sots)psühholoog.

-   probleem pärisandmetega - eetiliselt ja legaalselt hall ala, ja
    probleem: kui kvalitatiivselt uurida, siis on sama mis konsentita
    eksperiment, kui kvantitatiivselt, siis ei saa ilmselt kätte olulisi
    tunnuseid nagu rahvus, piltide ja tekstide sisu ja mõte.

-   midagi iterated learninguga teha, kui fookuseks oleks meemide
    kujunemine. või ka profiilide kujunemine, nt generatsioonide kaupa,
    skoorida matche, ja lasta inimestel enda (või ka miks mitte varasema
    generatsiooni) profiile tuunida vastavalt tagasisidele (pmst saaks
    ju lasta valida, et davai võta siit valikute hulgast see profiil,
    millega sa samastud... probleem ainult et äkki kõik tahavad
    supermodellid olla...).

-   konkreetsemat küsimust on vaja kui lihtsalt "kuidas ennast
    esitatakse".

-   vt Kristjan Kask psühholoogiast, ilmselt TLÜs kõige lähem, on teinud
    nägudega midagi, age perceptions jms

-   ok uuris välja mingi eetika.

-   tinder data from multiple countries right; so that would allow
    comparing e.g. Estonian Estonians, Estonian Russians, Russians
    Russians, Finns, Latvians etc? And see if they cluster primarily by
    gender, country or ethnicity (inferrable to some extent from names &
    bio language) That sounds like something that might be of interest
    to the general public as well. One way to make all these groups (or
    any groups) directly comparable would be to transform all the data
    into a single language (English is easiest) using machine
    translation (I've been talking to some Tartu NLP people, they got a
    new API for their multilanguage neural translator which seems faster
    than the old one I recently complained about in one of the
    meetings). So free bio text from any language becomes a set of
    English sentences, the "tags" feature profiles have are English
    anyway (treat them possibly as a sentence), and then your image
    recognition tools yield further tags, another "sentence" per image.
    Why I'm talking about sentences is that you could use a pretrained
    BERT model (which is a sentence-centric thing) to transform these
    into vector, treat each profile as a document (in the topic
    modelling sense), and then use the profile vectors for clustering
    (or also sort of topic modelling if you'd like). And then see which
    of country/gender/age/ethnicity or a combination of those best
    predicts cluster differences, or in more concrete questions, are for
    example Estonian Russian speakers more like Estonians or
    Russian-Russians in terms of their self-presentation - and I'm sure
    there's been sociological studies into this, so you can build on
    those and test hypotheses which have been (very likely) put forward
    based on magnitudes smaller samples sizes (I doubt any socio people
    have had the time to do focus interviews with 60k people;).

-   ja sinna juurde mingi tsne/umap plot riikidest?




## Mark

-   tegelikult see asi vist on ka üsna see sama
    informativeness-complexity, kui täpselt/paljudeks kedagi või midagi
    jaotada, rahvaid, rasse, kultuure jms. kui seda korpustega teha,
    siis saaks kommvajaduse kohe ju arvutada. iseasi kuidas neid
    viitamisi kõiki kätte saada, aga embeddingutest peaks sarnased kätte
    saama, ja siis saaks käsitsi kodeerida.
- kui ekspressi asjast artikkel teha, siis võibolla viidata: 
    - terminology used by fake news, Longhi, Julien. “Mapping Information and Identifying Disinformation Based on Digital Humanities Methods: From Accuracy to Plasticity.” Digital Scholarship in the Humanities 36, no. 4 (December 1, 2021): 980–98. https://doi.org/10.1093/llc/fqab005  
    - A Great Divide: Polish media discourse on migration, 2015–2018 https://www.nature.com/articles/s41599-021-01027-x
- võibolla lihtsam polariseerumise mudel, pmst custom sentiment sõnastik + w2v vektorite järgi: https://aclanthology.org/2021.emnlp-main.788/ 
- Kas see oleks ka sarnane: Grand et al Semantic projection recovers rich human knowledge of multiple object features from word embeddings https://www.nature.com/articles/s41562-022-01316-8.pdf?proof=tConcernant
- Matteo jutuajamine: https://docs.google.com/document/d/1-m_dNntBKg0pJCPqEwC8SC50ApLouwofO4KBHTmk1Gk/edit

## Antonina

-   tuleb välja et luges Monica artikli läbi ja oleks huvitatud sarnase
    asja tegemisest, kasvõi replitseeriks, Monica ütleb artiklis et ei
    tea äkki päriskunstnikud käituks teisiti. kuidas läbi viia muidugi
    praegu küsimus; kohapeal ei saa, mõtlesin et äkki kunstnikel
    tabletid aga arvab et ei pruugi ja pole ka nii lihtne kasutada.

    -   oleks ka sarnane Thomas Mülleri redditiartikliga,
        <https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0202019>

## Mila

-   pakkusin et äkki tahaks oma pseudoajaloo asjaga teha sellist värki:
    teha iga narratiivi kohta mingi keywordide (bigrammide,
    skipgrammide) kogu, ja siis sellega klassifitseerida, kas tekst x on
    narratiivis y, ja siis saaks vaadata kuidas need levivad. Või
    võibolla mingi parem keelemudel kust välja tõmmata mingi topik või
    layer mis esindab seda narratiivi, st on treenitud/tuunitud
    eksplitsiitselt tekstide peal, kus iga tekst on kodeeritud kui x
    narratiiv, või tähe/sõnapõhine CNN mis on selle treeningseti peal
    tehtud. mõlematpidi käsitöö: kas teha mingi fraaside sett, või
    kodeerida tekstijuppide lipukesed.
-   päris huvitav mõte: narratiiv on see, et varasemad ühiskonnad olid
    jube usklikud ja müüdikesksed - samas tundub et just praegu usuvad
    pooled inimesed mingeid veidraid müüte, a la lamemaalased, QAnon,
    vaktsiinivastased, trumpistid ja muud lollakad.

## Peeter

-   teeb tegelikult sarnast asja mis mina, klassifitseerib tekstijuppe,
    aga rohkem sentimenti; on mingi leksikon olemas.

-   pakkusin et: kui tahta kontekstitundlikku klassifitseerimist a la
    <https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b>
    aga näitete kodeerimine jäi toppama/oli probleemne, siis vahepealne
    variant oleks veel, et kasutada seda lipikutega leksikoni, et
    genereerida treeningsett: otsida/matchida lõike, kus on min 1 või
    min 2 ühe klassi sõna, ja mitte ühegi teise klassi sõnu (või natuke
    peenem: kus üle teatava skoori, mis on seal sees olevate
    klassisõnade skooride summa, ja sõna skoor on tema -log(sagedus),
    ehk good on väikse kaaluga samas mõni spetsiifiline nagu magnificent
    on suurema kaaluga). Seal mõni mõnituhat välja niiviisi võtta
    treeningsetiks (võibolla mingi sadakond läbi lugeda et kindel olla
    et selline filter/otsing ok tulemuse annab), ja mingi mõnisada
    testiks, ja siis mudeliga saab ülejäänud korpust tagida. Sel juhul
    muidugi peaks kindlasti selle snippide LCS filtri tegema et ei
    tekiks varianti et testitakse treeningseti peal jne.

## Vejune

-   see soolise jaotumise teema, kas ERRi või nüüd BMMG korpustes. saaks
    parsida nimed, võrrelda eesti ajakirjanduskoolide lõpetanute
    nimekirjadega. huvitav kas meil on ka daversity, nt mativersity?
    (saaks võrrelda nimestatistika andmebaasidega, kes on üleesindatud)


### Cinando

- peaks UMAPis panema ankrud (genre: ainult-action, ainult-dok jne) et oleks lihtsam interpreteerida
- Indrek tahab top festivale, Vejune kõiki, aga saaks panna kõik, lihtsalt väiksed on hallid ja taustal.

- Mike&Folgert: saaks kasutada mingeid occupany/instance või traps mudeleid et ennustada mis on tegelik diversity (sh need kes festivalidele ei pääse). Chico: "Film traps: you offer a trophy and some money, and people just send their films there!".

- mudelleerida festivale keele, zanri ja maa latentsetes ruumides.
- zanr: kas co-occurrence või doc-term? tfidf või ppmi või lda?
- maa: koordinaadid, + võrrelda festivali-punkti maade-keskmisega.


Descriptive:
- number of film entries vs n of unique categories over time. e.g. per year. see if correlate.
- growth of diversity - langs, countries, does it correlate?
- counts first on messy data, analysis later on clean

- what is here we show? - large scale overview of the festival landscape. describe how festivals differ.

- hyp: markets more variable / more entropy than festivals in programming (lang, genr), also quality (but can't measure). can we test?
   - remove library type entries, compare.


Festival space?
- festivals move across genre/lang landscape.
- moves adaption to industry? but what is industry?
- something about fest vs mark network differences
- festivals are not equal, cannes is more like market (mixed), but festivals specialize more. (does festival entropy predict market entropy? different for top vs genre festivals - but also only top have markets so maybe not)
- 2 metrics in space: A change relative to itself and space, or B change relative to average of the year.

See how a film enters a market and moves?
- temporal patterns, how different time between festivals
- see how many festival goes to. and compare between genre, lang, country, averages or medians.

- Q for minor lang filmmaker: do you try to go to cannes (mainstream) or try to target your "own" in terms of geo or lang. But we can't really do that.

- vector of film by festivals, values are e.g. lang entropy of festival, or is-same-lang, then compare distrs acorss e.g. countries. can even include the smaller/messy festival entries, still gives some values. distr would be film-festival pairs.

- CONTROL FOR LENGTH! not all accept short films
- see how many shorts in data.


Market space 




## Mar

-   kui seda twitter asja teha, siis pmst mingi event prediction - et
    kas likes+retweets kasv ennustab müüki, või mingi eelnev aken.
-   peab kuidagi aega limiteerima
-   kolm küsimust/mudelit: kas üldse? kui kaua läheb? ja palju maksab? esimestesse hind mudelisse!
-   laikid pole ajaloolised, on eilsed
- edition: võib olla 10 koopiat või 100 vms
- baseline/control variaablid: editions, hashtags, cashtags, tweetlength
- limitations: pole ajaloolisi likes, retweets, followers; seega piirame lihtsalt aja-akent.





# Balti meediamonitooring

-   kristiina [Kristiina\@bmmg.ee](mailto:Kristiina@bmmg.ee) ja
    sven-erik (ceo)
-   tahavad nagu mingit asja, mis oleks sentiment analysis ja samas
    ennustaks mis on hea artikkel, AGA mitte kasutades
    klikkidestatistikat. et tahavad klikke, aga ei taha klikke lugeda,
    et liiga lihtsakoeline või madal -> ok see oli mingi üldine asi,
    pole probleem.
-   on: kõik ajalehed, kõik portaalid, suur osa raadiot (juba tekstina),
    2500 artiklit päevas
-   al 2013 3 riigi peale 230gb, 90% eesti meediast, eesti kuskil 70gb,
    metaandmed küljes autor, kuulajaid/lugejaid, meediatüüp, märkssõnad
    nagu pangakaart, mingi sfinx süsteem otsib mrksõnu.
-   võibolla lemmatiseeritud
-   postimehe grupi klikid
-   300 klienti, 8000 märksõna, sh nimed, terminid
-   teevad käsitsi, on märgendanud aga terveid artikleid
-   nt PPA: juhi nimi, firma nimi, politsei - aga ei taha välisuudiseid,
    seega tehakse käsitsi, et poleks usa politsei. a nt välisminister -
    tahetakse eesti oma, aga meedias mainitakse muude riikide omasid.
-   tartu stakk jama teinud. aga annavad dokumentatsiooni üle paari
    nädala pärast.
-   järgmine nädal teada kas andmeid saab.

I've had a chat with a BMMG rep. Here is a short summary of what we
talked about and where we stand. Basically they are considering giving
us lots of good data, and want better solutions in return. Most of the
solutions probably come down to implementing better natural language
processing pipelines. This is something we might make use of ourselves
too if we had them, e.g. the conversation we had yesterday with Mila -
detecting narratives is in principle a similar classification task to
detecting topics and not far from detecting sentiment. - What we could
get IF(!) their boss gives the green light (some time next week): -
Estonian written and online media plus radio news transcripts, covering
90%+ of daily published news and stories, 2013-2021. They also have the
same for Latvian and Lithuanian. Comes with metadata like authors,
publication, genre, finegrained keywords, and number of clicks in the
case of Postimees Group publications. In plain text format, with some
minimal html markup. Possibly lemmatized, if not we can lemmatize
outselves with EstNLTK. About 70GB total, 2500 items (articles, radio
shows) per day, so around 6 million items total. - They have about 300
clients and keep track of about 8000 keywords/entities for them (by
manually searching for them every day in their databse and filtering out
irrelevant things, then sending the relevant articles over to their
clients at the end of the day), so there's some of that info in there. -
Additionally, training sets they've compiled, but she said most of them
are useless, scoring sentiment for an entity that occurs in a text, but
for an entire article. Later ones more useful, sentiment scores on
paragraph level, she mentioned one with 7000 labelled snippets. - What
they want: - better sentiment analysis/classfication for mentions of
keywords and entities of interest. She mentioned their supposedly
data-science partner (STACC) implemented something that got around 80%
accuracy... which is about the same as what she got after doing a
beginner python tutorial and implementing the most basic Naive Bayes. So
they're not happy, particularly since STACC is supposed to be this
leading data science company. - better topic modelling for prevalence of
topics over time. Again, their partner did something (we'd have access
to their documentation in 2 weeks, so we'd know what, but something
using LDA), but she said the topics they got was useless to them. This
is tricky, would need to figure out what is it that they really want to
see/get. - better, more contextual keyword retrieval - e.g. a client may
be interested in all articles that mention the Estonian police, but they
don't care about news about police of other countries, so just matching
"politsei" yields suboptimal results (all right recall but low
precision). They do it using fixed manual keywords, haven't tried
anything with word embeddings or text similarity/classification models.
- Possible further cooperation opporunities: they have lots of
annotation work going in, some requires understanding of media and
language, some requires basic IT skills instead, they'd are in principle
interested in hiring interns, which is something that TLÜ students might
be interested in, if they have mandatory internship credits in their
study programme (I think some do). - It sounds a bit like what they
really need is just a better data science/NLP company partner, but if
even STACC sucks that bad (don't quote me on that), maybe the industrial
level is not that high either. So we might be able to do something, and
having the data would be nice of course, if any of us has ideas what to
do with it (mind you, that would likely mean the ERR data we have been
promised for a while is not that crucial anymore, as it's just a drop
inside the sea of the BMMG dataset - could still of course keep talking
to ERR for outreach purposes). Personally, I know how to implement some
of the things they (probably) want, but I don't have experience with all
of the deep learning'y things which I anticipate might improve their
results, so bringing in a proper NLP computer scientist at some point
might be something to think about. Also I'm not sure if I'd (or any of
you would) be very motivated to spend months fine-tuning a topic model
to meet the vague target of what "makes sense" to a particular company
based on the probably equally vague demands of their clients. We'd need
to find something that would be also clearly and directly useful for our
scientific output for this to be worth it, nice data or not (unless we
want to form a startup instead and make big bucks of course).

-   huvitav kas seda nende nimede-matchimse probleemi (PPA'd huvitab
    eesti politsei mitte usa vms politsei) saaks samamoodi
    kontektstitundliku bertiga lahendada, et võtta port õigeid mainimisi
    ja ports valesid (kui nad neid päevadeviisi sordivad, kas huvitav
    mingit logi ka sellest jääb). äkki peaks proovima korra ise
    implementeerida, et saaks aimu kui hästi töötab.
-   kas äkki see aastakokkuvõtte-topikmudeldamine võiks olla hoopis
    klasterdamisega, kus klastrite keskmed on hoopis need nende enda
    märksõnad, ja topik on ports sõnu nende ümber, võetud tavalisest
    type embeddingust? nt treenida fasttext sama korpuse peal. ja siis
    prevalence on lihtsalt nende sõnaparvede sageduste summa üle
    aastate.
-   ja kõik muu bertiga? estbert on olemas, vajab ainult sisendi
    lemmatiseerimist. mingi ernie tundub suht highlevel api.
-   äkki hierarchical lda, rekursiivne
    <https://www.aclweb.org/anthology/W14-3111.pdf>, ja siis võtta välja
    keywordid ja näitepealkirjad, pealkirjad nt tehes tfidf või ppmi
    doc-topic maatriksile. äkki topikute arvu saaks kuidagi BMMG
    metadatast tuletada, neil peaks ju mingi arusaam olema?
-   äkki siin saaks ka Tillmanni või Mar'i kasutada, pmst ju uudiste
    kureerimine ja uudiste latentses ruumis liikumine?
-   või siis üldse networkid:
    <https://advances.sciencemag.org/content/4/7/eaaq1360> - ütleb et k
    tuleb automaatselt ja kohe on ka hierarhiline.
-   <https://www.aclweb.org/anthology/2020.emnlp-main.135.pdf> ütlevad
    et word embeddingud kõlbavad ka; doc2vec töötab ka täitsa ok

# Public value, cinando, err

-   Leskovec, Jure, Lada A. Adamic, and Bernardo A. Huberman. "The
    dynamics of viral marketing." *ACM Transactions on the Web
    (TWEB)* 1, no. 1 (2007): 5-es. J. McAuley and J. Leskovec. [From
    amateurs to connoisseurs: modeling the evolution of user expertise
    through online
    reviews](http://i.stanford.edu/~julian/pdfs/www13.pdf). WWW, 2013.
-   bbc raport
    <https://www.ucl.ac.uk/bartlett/public-purpose/sites/public-purpose/files/final-bbc-report-6_jan.pdf>
    
## 25.11.2021 kohtumine pärast plotte

- tahavad mingit väikeste ja suurte võrdlust
- duplikaadid
- budget normida gptga?
- tahab et filmi lifecycle
- airline films
- paper 1 intention to sell.
    - general description
    - case studies: comparision between country size, region, language, budget, small vs big over time. where do east eur countries sell.
    
## 17.01.2021 jutt Vejunega, cinando

- fookus festivalidele, sest filmid on hägused, raske võrrelda (pluss see et ilmselt isegi kui grupeerida, pole päris võrreldavad, väga erinevad kategooriad)
- festivalide puhul teha ennustav mudel, et mis tüüpi film kuhu festivalile tõenäoliselt saab (ja mis/kus auhinda saab)
    - mingi multinomiaalne (response on festival) või mingi random forest tüüpi asi, või eraldi binom mudel iga festivali jaoks :( või midagi muud, aga lõpuks oleks asi, kuhu param/var sisestada ja tulevad tõenäosused iga festivali kohta
    - ja mitte lihtsalt festival, vaid ka kategooriad/sektsioonid per festival
    - 
    
    


# Drift ja selection, Richard&Juan

-   eesti keele muutusi:
    <https://www.etis.ee/Portal/Publications/Display/e5eebf1c-bf87-4560-a2e0-3275767b649a> -
    võibolla see kokkukirjutamine; käändevormid kõik kipuvad kattuma
    (v.ä mägesid tüüp? aga need on ilmselt harvad), igasugu
    kõnekeelsused ilmselt 100a kirjakeele korpuses puuduvad.
-   kas inglise keeles on häid kokkukirjutusnäiteid?

## 09.03.2021

-   Juan vaatab edasi mida meetodiga veel teha. Küsimus et millele siis
    rakendada. Vaatame google booksi. Richard ei tundu vaimustuses
    bioloogiateemadest, aga äkki kultuur...? maalizanrid vmss
   
# kui meedia/kultuuri peal teha

- erri andmete peal?
- vt https://www.cambridge.org/core/journals/evolutionary-human-sciences/article/culture-without-copying-or-selection/4A0AD3781ED1616BD9D9424BD02FDCB4
    
# Competition artikkel ära lõpetada

- kas see lähima-n suhtmuutus vs advection, või üks variant veel, et kõik aegread ära normida advectioniga ja siis vaadata mis muutub st üle/alla baseline, ja millega see võistleb - pmst siis saaks vana competition ideed kasutada, sest ühised-ülesminekud peaks olema ära nullitud... aga seda transformitud aegridade võistlust oleks ilmselt päris raske müüa.
- kui ppmi advection, siis peaks iga korpuse peal optimeerima k eraldi.
- eesti korpus korda
- viita Bates, Elizabeth and Brian MacWhinney. 1987. Competition, variation and language learning. Mechanisms of language acquisition, ed. Brian MacWhinney, 157-93. Hillsdale, NJ: Lawrence Erlbaum. &&& Bates, Elizabeth and Brian MacWhinney. 1989. Functionalism and the competition model. The crosslinguistic study of sentence processing, ed. Brian MacWhinney and Elizabeth Bates, 3-73. Cambridge: Cambridge University Press.



# Edasi: äkki sem-muutused vene jms keeles vs pärismaailma konfliktid

- https://arxiv.org/abs/1909.09907 Generating Timelines by Modeling Semantic Change
Analysing Lexical Semantic Change
- https://arxiv.org/pdf/2004.14118.pdf with Contextualised Word Representations


# Metateadus

-   Max tahab mingit embeddingut sellest Cultural Science Journalist.
    Äkki mõte, et teeks mingi topikmudeli kõigi nende erinevate DH tüüpi
    asjade peale, nt see CSJ, ADHO abstraktikogumikud, mõni DH ajakiri,
    ja siis misiganes CDA on. Ja võibolla taustal standartsemad, nagu
    ajalugu, keeleteadus, igasugu media studies. Et mis siis millele
    sarnane on/kattub, ja kas mingi erinevus on üldse neil.

# Õpetamine

-   04.03 väike ettekanne endast, kuskil selle ja mai vahel 2h
-   26.04 soovita kirjandust, 5, mingi õpik, midagi uut, ja midagi
    võibolla põnevat nt how charts lie
-   peaks hiirele mulli ümber panema
-   ja kasutama seda mis tartuski, mingi avalik markdown, kuhu lasta
    panna vastused
-   kunagi peaks tgeema, et kõigepealt teevad paberil
-   kuidas saaks nii, et nad saaks omavahel jutustada paralleelselt


# Bisnes

## variante

Maarja-Liisalt:
1. https://eestikonverentsikeskus.ee/event/arenguprogramm-andmeanaluutiku-edasijoudnutele/
2. https://centar.ee/koolitused/analuusitarkvara-r-praktiline-kasutamine
3. https://koolitus.ee/koolitused/koolitus-introduction-to-r

- ülikooli lühikesed vahendatud kursused, Elina Tahvel - TÜHI teadmussiire, vahendavad koolitusi, võibolla 20% võtavad

## Lithme WG1 industry-academia collab seminar

- often overpromising: academics too confident with offers, later disappointment

- don't devalue intellectual property (but how to value?)
- DCUs on oma tech transfer office ja neil omakorda on oma firma, DCU Invent, kust spioute teha, kui need on börsile läinud siis on osa aktsiaid jäänud, ja sellega ülikool teenib
- If no formal TTO then talk to research office.
- always with contract, set dates, limit liability, proper NDAs if needed. which country's law applies. Don't blast in with NDAs, but might be needed. Contract should have publication clause. Figure out what will be open source and what not. If using open source libraries etc also make sure they know, some scared of that, they can't monetize; might commit to not using but don't take liability, they have to ensure they don't breach copyright etc.
- who retains rights if multiple?
- patent: 20 years, need to apply. copyright is automatic (time varies, lifetime+n years). Trademark: use it to assert or register first. Registred design is similar but only the appearance of thing (like crocs), register. Trade secret: like recipes.
- Code has copyright, but applies to expression, can bypass by rewriting, not very strong
- Products like phone often contain multiple IPs: trademarks, patents
- copyright and patents - a kui mitu inimest projekti peal?
- Moral rights: paternity (right to be identified as author), integrity (right not to be misprepresented, distorted; Wall Street bull example), false attribution (can't say I did it if I didn't). Automatic but can all be waived.
- Patents. The "social contract": I reveal invention but then others can't make it. But open source? Publication negates, incl conference?
- Patent by default just in application country, but there's Patent Cooperation Treaty, and European PO (but still needs for each country). Takes 12 months to PCT, at 16 international search report, 18 international publication, 22 demand for prelim examination, 28 prelim report, after month 30 national phase (do in every country). Costs a lot of money. Parallel process: can publish paper in the meanwhile; submit initial IDF when writing up; if filed before publication then fine; if after no point. Initial filing <5000 eur, PCT 7000, after 30 months every territory 2k per territory. Depends how complicated patent; might need patent attorney. Some places have academic patent funds.


Datadoi. It's a data repository
similar to OSF, Zenoto, Figshare etc, but hosted by the Tartu University
library <https://datadoi.ee/>. It's basically meant as a place to keep
data related to publications, so that it stays available even after the
project has ended. They're in the progress of revamping it to be not so
Tartu Uni centric; right now there's TÜ logos all over it. It's a bit of
a WIP otherwise too, the interface has English support but the
instructions are still in Estonian (the English instructions video is
apparently outdated). Also no advanced search right now, can either
search by free text or browse by collections. They said they intend to
fix it. They said they're linked to and follow the standards of
something called Open Air, I don't know what that is; and something else
too but I didn't catch it. And are visible on google (I tried to search
for a few datasets). Data is uploaded to collections under communities,
we'd go under the TLÜ node, which has subcommunities for institutes; we
could also apply to create collections, e.g. a CUDAN one, and/or
possibly collections for projects. If we were to use it, it might make
sense to apply to make CUDAN a community since it's across schools. Data
is uploaded to a single community/collection, but can be mapped to
others after that to make it visible under multiple ones (e.g. if
authors from multiple places). The TLÜ node is currently on the same
level as the four faculties of Tartu Uni (which are Humaniora, Medicina,
Realia, Socialia). Actually I'm a bit unsure what's the difference
though, since TÜ institutes are collections under their faculty
community, while TLÜ institutes are subcommunities under the TLÜ
community. When you make an account, you can't immediately upload, need
rights from the admin of your relevant collection/community. The admin
is the scientific coordinator (teaduskoordinaator) of each
institute/community, e.g. in the case of TÜHI it's Kerstin Liiva
[kerstin.liiva\@tlu.ee](mailto:kerstin.liiva@tlu.ee){.email} Uploads can
be tied together with DOIs, either that of the paper the data links
with, or with another data object. If upload comprises of multiple
files, they recommend zipping it; apparently if it's 50+ items under one
item it gets slow for users browsing your item (for some reason). If you
want a DOI for each item in your dataset, then they have to be uploaded
as separate items, but can be linked together with the DOI reference
field and/or by creating a subcollection for just that dataset (again,
by applying to the collection admin). For users max upload size is 2gb
per item, to upload bigger files need to contact them. I asked what's
the max size per user or per item, they said there's no upper limit so
far and even like a 2tb should be fine. Also they can be contacted
directly for any issues if the scientific coordinator is not replying or
doesn't know how to help. They sound helpful, and can be probably
reasoned with if we need something. That seems to be their main selling
point too. There was an option to send questions in advance, which I
did, and it turned out I was the only one who did, they started with
that and didn't sound... too happy that I had asked what would be the
advantages of using their service over something big and international
like OSF. I sensed a bit of typical Estonian inferiority complex in
there - this is a typical thing that comes up around here, why should
anybody use something Estonian or do something in Estonia, instead of
doing/using something (assumedly) bigger&better outside. I felt like it
was an important question to ask though, and tried my best to express my
appreciation for an informative session at the end. Their answer was
that basically there's no technical advantages but that they're
available and ready to help, and aim for staying the same for a long
time, and if anything does change, TLÜ people would get direct
notification as they're collaborating with the TÜ library; while they
speculated that big foreign things like Zenodo or OSF might change their
model or ownership at some point and then there's nobody to complain to.
I don't know anything about that last bit so can't comment.




# lambimõtted

- pmst Wizard, aga tegelased on kõik akadeemilised, ja suhted on keerulisemad, umbes nagu see dragon ja fairy (Jubiläumsedition) aga veel midagi. võidud on numbrid, ennustad mitu milli raha saad. the unit is millions... of something. pildid saab stable diffusionist, teha kickstarter ja davai.

-   servis akadeemikutele veebilehe tegemiseks, mingi lihtne markdown v
    wordpress mida saaks ise muuta, githubi vms kohta üles ja suva. äkki
    seotud sarnase social media visibility õpetamisega, ja siis
    reklaamiks et näe teenus ka.
-   translaator mis muudab inglise keele x-tongish'iks, võttes (osad)
    sõnad ükshaaval ja tõlkides neid, et tuleks otsetõlked, nt
    estonglish oleks "it is very light to go with bus into theatre".
    mõttetu aga hea meemimaterjal. võibolla kuidagi keeleõppeks ka, et
    kuidas mitte teha/paranda vead?
-   genkunst. idee: mapitud semruumi aga iga kord uus umap/tsne; ja
    sõnad ainult igaüks üks kord, ja igast sõnast voolab välja particle,
    kui sagedasem sõna siis rohkem; värvipalett tähtsamate sõnade järgi
    (tfidf mingi korpuse vastu?). particle trace nii kuidagi, et ei
    kattuks, mingi repulsor igal sammul, või maastik muuta punkti ümber
    et teine particle ei tuleks sama ruudu peale. mustal taustal nagu
    need lilledega natüürmordid.
-   äpp nagu softmurmur aga insenäri/kodeerimise/leiutamise suunaga,
    pmst mingid saundtrakid nagu iron man ja pacific rim ost, pluss
    võimalikud taustahääled
-   sometimes when I'm struggling with a complicated programming or
    datawrangling task, I leave myself little print()s in the code so
    that when it finally works, I can sit back turn up Iron Man 1 OST
    and watch msgs scroll like "Initiating multicore processing" "61884
    vectors loaded" "Compressor engine Mark III online" "Commencing
    phase 1"
-   Writing a paper with 5 Coauthors, 3 unfamiliar with Latex. Suggested
    using Overleaf, after a short period of getting used to it they're
    saying it's actually ok. A little Rich Text Mode can do wonders. ...
    (tbf I did hide most of the nightmare horror latex code in a secret
    little preamble file but sshh)
    
-   ruumifonoloogia. igast ruumi punktist igasse teise punkti on mingi x kaugus. selle saaks mappida sagedustele vms helipikkustele. igal ruumil oma heli (kuubik vs katedraal) või skaala. selle peale arpeggiod vms lihtne kompositsioon. mõttetu aga äkki äge? sama asi tekstiga - sõnapikkused mappida helisagedustele?
- taustaheli-sait - nüüd kus on pildi ja varsti äkki muusika-genereerimine, saaks lihtsalt taustamussi genereerida, pluss helid nagu vihm, kohvik jne.

- mis saab, kui pildimudelile nagu stable dif või tekstimudelile nagu gpt/bert sööta treeninguks ette materjali, mida eelmine versioon on tootnud/genereerinud, kas ja kui kiiresti keelemuutus tuleb või pildid imelikuks lähevad.



# Edasi

-   kui granti kirjutada peab diagrammis feedback loop sees olema muidu
    kohe küsitakse.vms.
-   marie curie min aasta enne lõpetamist, st kuskil 2022 keskel
-   raha. nordplus: vaata et liiga vähe ei küsi, 10k võib vähe olla. nordplusi leht annab häid juhiseid.
-   raha, put ja stardigrant. peab olema ühiskondlik impact ja data management sees. Indrek ütleb et hea kui support letterid ka kui kuskilt vähegi saab.
- veebruaris https://balticamericanfreedomfoundation.org/programs-awards-research/ kuni 12 kuud usas, aga pärast 2a eestis.

## ERC Synergy

- kuni 8.nov. 
- peab näitama sünergiat, et üksi ei saaks, koos vaja teha kindlasti; "exceptional combination of knowledge". aga võib olla teine teadlane sama koridori pealt. any career stage PIs, kõik võrdsed pmst. max 1 PI võib olla väljaspoolt EUd lisaks.
- EI ole syn kui lihtsalt andmeid vahetatakse või niisama networking. ei pea olema täiesti eri aladelt, aga peab näitama ekspertiiside kombot.
- iga PI host uni peab andma toetuskirja.
- journal impact factor enam ei loe, tuleb panna achievements, ja saab ka väikse jutu juurde panna seletuseks.
- covidit võib mainida, sama mis career breaks. p
- peab olema gender equality plan.
- kui 2022 saab C hindeks, siis Sdg ja Adg 2023 ei saa uuesti. Kui A/B siis ok uuesti proovida. PI võib olla ainult ühes. Et proovida 2023 ja praegu on, peab vana nov2025 lõppema.
- peab olema feasible aga samas high risk high gain.


## TLÜ uuringufond 

kuulutas välja uue konkursi toetamaks konkurentsipõhise rahastuse toomisel edukate uurimisrühmade toimetulekut perioodidel, mil kõrgetasemelisi taotlusi on esitatud, kuid kõrgest konkurentsist tulenevalt on uurimisrühma projektipõhine rahastus oluliselt langenud (edaspidi projektimeeskondade sildfinantseerimine).
Konkursi tingimused:
-          Eraldatakse ainult ühekordseid toetusi, projekti kestvus kuni 1 aasta.
-          Taotlusvooru maht on kuni 100 000 eurot.
-          Taotluste esitamine ja hindamine toimub vastavalt TLÜ uuringufondi eesmärke teenivate projektide konkursside tingimustele ja korrale.
-          Taotluste esitamise tähtaeg on 14. november 2022 ning taotlus tuleb esitada läbi WD.
-          Materjalid on siseveebis: https://siseveeb.tlu.ee/cms/viewpage/?menu_id=16112835&key=teadus&page=menus



## Kultuuriteooria seminarilt

- 02.02.2023 ERC consolidator, 14.03 Horizon, märts 2023 ETAG PUT, kevad 2023 Interreg Cental Baltic(?), sept 2023 sügisene Horizon, sept 2023 Marie Curie (saaks väljast siia meelitda, aga peab olema MSCA taotlus, enam ETAGi sissetulevat postdokki pole - aga kui Curiet ei saa siis ETAG võib rahastata ikkagi kui on nutika spetsialiseerumise ala). Okt 2023 tõenäoliselt ERC Starter, tavaliselt sügisel.
- Peaks selgeks saama data management plaani (ei tohi olla google/ms/dropbox vms usa kompanii) ja ethics plaani tegemise.
- kui teha ERC avaldus siis peaks sama proovima ka ETAGisse saata
- ETAGis saab korraga üks projekt olla (mujalt raha ei sega)
- ETAGis võiks mingi eesti fookus olla, aga pmst ei pea kui muidu tugev.
- ERC starter olevat madalama konkurentsiga (aga mingi 2-7a pärast dokki)
- Horizon 14.03.2023 etteantud teemad, vajab rahvusvahelist gruppi. 21.09.23 mingi suurem heritage oma. Sügisel mingi emotional politics teema ka.
- Horizoni lehel olevat networkingu-üritused.
- Postimehe fond mingi ~50-100k/aasta. peab olema kas rahvusteadus või "ajakirjanikuhariduse ja -harituse toetamiseks"
- Marek ETAGist: peaks uuesti proovima, hakkama praegu juba ette valmistama (osadel juba praegu seminarid) ja tagasiside läbi töötama. Ideaalis 2 avaldust, üks rühma ja üks starter, pärast saab korrigeerida keda tegelikult tööle võtta. Aga hinnatakse avaldajat ennast ka, kui pole 5+ excellent siis ei saa (Maxil ei pruugi piisavalt väljundit olla). Üldse: vahet pole mida algul kirjeldada sest raporteerimist pole, pärast tagasiside isegi kui neg siis vahet pole sest järgmises voorus kedagi ei huvita, loevad pigem kvantitatiivsed hinnangud (artiklid jne). Marek ütleb et pole mõtet ümmargust pulka kandilisse auku ajada, vaid pakkuda algul kandiline ja siis pärast ise ümmarguseks teha. Võiks olla mingid eesti asjad ka taotluses (et kasulik riigile/ühiskonnale). TÜHI teaduskoordinaatori käest võib tehnilisi küsimusi küsida, Liisi Keedus on ETAGi komisjonilt, pmst võiks üritada peilida sisu kohta; Indrek ja Marek on mõlemad nõus nii tagasisidet arutama kui avaldust üle lugema.

## Horizon, twinning

- konsortsiumid ja matchimine https://cluster-2-brokerage-event.b2match.io/home 
- Tuuli ütleb et tasuks seda twinningut vaadata, peaks lihtne olema, idaeuroopale mõeldud, lääne uhket partnerit vaja, aga midagi et suur protsent on õpetamisel-arendamisel (aga äkki saaks selle raames selle quant-qual artikli teha?)


## Horizon Kultuur Loovus Kaasav Ühiskond tutvustus 19.12.2021

- oodatakse kiireid lahendusi probleemidele, mingi rakenduslik väljund ka.
- hinnatakse ainult küsitud asja raames, kui mingid ekstrad/teemavälised, siis neid ei hinnata. SAMAS näitemees ütleb et hea kui on nii eripärane et jääb silma, natuke piirist üle, aga samas ikkagi call'i raames. ETAGil on konsultandid ka. interdistsiplinaarsus on väga hea.
- kui konkreetne küsimus, siis tuleb ka palju väga sarnaseid taotlusi. mõelda kuidas midagi paremini pakkuda (lisaks et vastab nõuetele), aga juurde/lisaks pakkuda ka ei ole mõtet. Hindaja jaoks lihtsaks teha, öelda kohe miks just mina.
- kui teema kirjelduses "should" siis peab, kui "could" siis on lihtsalt näide.
- partnerid ükskõik kus EUs + UK mis nüüd uuesti liitumas, "assotsieerunud riigid" 16 varsti veel 4. 
- pakkuda kas "minu teema ja projekt" või "minu nišš laiemas konkursiteemas või projektis", ehk kas olla keskne pakkuja või üks osaline.
- cordis: https://cordis.europa.eu/programme/id/H2020-EC - saab vaadata varasemaid projekte.
- saab regada hindajaks, soovitavad et selle kaudu saab õppida.
- IMPACTOUR näide, panid kokku kolm asja, meetod data stakeholders. pmst meetodiarendus, neil oli masinõpe rakendatud stakeholderite otsuste tegemise aitamiseks. näitavad et kasulik, state of the art meetodid, näidata et hea koht kus seda tööd teha (nt eestis: positsioneerimine, digivärk). näitasid et mis alal kasulik - environment, resilience, econ, socioecon jne.
- lisaks partneritele kaasasid regioone, nt tartu ja võru, mujalt ka konsortsiumis euroopas, et nad ei saa projektist midagi, aga välised partnerid/piloodid, see hindajatele meeldib.
- vahel hea kui mingi hea iva väljendt, nt mingid targa linna omad pakkusid "smartofka", ehk smart linn + hrusofka.
- partnerid: kui konkurss ütleb 3-4, siis parem kümmekond. ei pea olema ülikoolid ainult, igasugu instituudid ka. kust leida: varasemad koostööprojektid samas ülikoolis, tuleb küsida. kasusaajad peaks olema ka konsortsiumis esindatud.





## Mõte sellest quant+qual artiklist/õpetamisest

- "feature analysis", "usage-feature analysis", "multi-factorial analysis" in linguistics
- gries "Multifactorial Analysis in Corpus Linguistics: A Study of Particle Placement
- A multifactorial corpus analysis of adjective order in English
- Bresnan 2007. Desagulier: When a linguistic phenomenon is influenced by several factors at the same time, its analysis is multifactorial. Experience tells us that, arguably, just about anything in language is multifactorial. Once operationalized by the linguist, these multiple factors are captured by means of several independent variables. When observations of the linguistic phenomenon are captured by several variables, the analysis is multivariate.
- Content Analysis in an Era of Big Data: A Hybrid Approach to Computational and Manual Methods https://doi.org/10.1080/08838151.2012.761702

- "coding" of "variables" and then regression, e.g. "We also coded the data for position in the clause" (@lauren_bliksem et al 2016)
- Szmrecsanyi 2016: "the dataset were richly annotated for a range of contextual constraints or conditioning factors", and then regression
- Casimir,Tobi,Tamás2022 mention "thematic content analysis/../ attaching codes to text that capture meaning/../ akin to measurement in natural & life sciences" which may feed into "descriptive & correlational statistics"
- Jack: Just ‘data analysis’? Like it seems to me to be a basic data analysis workflow: data collection, data coding, statistical analysis.
- Processing pipeline
-  would just call the first part annotation

- cinemetrics pmst mingi selline filmide kohta
- nt Tinitsa ja Olegi filmiartikkel
- mixed methods, Katrin Niglas
- behavioural profiles semantikas




# Grant

- etag: väidetavalt multidistsiplinaarsus pole hea aga interdistsiplinaarsus on hea.

- https://arxiv.org/abs/2212.05856  "I think this is the most disruptive technology": Exploring Sentiments of ChatGPT Early Adopters using Twitter Data

## chatgpt

- alati natuke erinev tulemus, aga kas probleem?
- kas probleem et ei tea mis versioon
- api kaudu samas fikseeritud
- ei saa liigselt kritiseerida, tigedad reaktsioonid
- a et kui maha võetakse
- should a black box AI replace
- teeb nt proge kiiremaks. enchance aga mitte replace vormuleering. milleks kasulik on.
- selle nurga alt ka et mis tehakse juba nagunii
- kas saab üldse uurida, kuidas uurida et oleks aega, et järgmine versioon ära ei käntselda.
- pole ainult asendus - seletab ka, explainable AI. saab võrrelda teistega, testida.
- kureerimise probleem. variatiivsus sureb. umbes nagu mood et kõik kannavad sama, kõik kuulavad spotify'd. 
- pmst on recommendation system moodi.


- õpetajaid vähe, kas aitaks.
- õpetajate õpetamine, tihti vastus õige kui hea prompt. tüüpülesanded, et mida näitena vaja.
- õpetada masina käest küsima, hindama vastust kas ok.
- võrrelda keelemudelite outputte, pmst benchmarkke õppimise jaoks. prompt engineering layeri vajadused.



- teema kaupa, õpetamine, fintech, finetuneb mudeleid töölisi asendama. anda inimestele rohkem aega et demokraatia jääks aega jääks.
- ai lindistab koosolekuid ja otsustab või tagasisidet. finetunitud mudel. või väikeinvestorite asemel, analüüsib. 

---kui tahta et cudan grant maksaks siis maxile 100 sõna





